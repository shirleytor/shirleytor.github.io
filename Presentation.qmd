---
title: "Presentation"
author: "Shirley Toribio"
subtitle: "December 9, 2024"
format:
  revealjs:
    scrollable: true
    slide-number: true
    show-slide-number: all
    embed-resources: true
execute:
  echo: true
  warning: false
  message: false
---

## Diversity of Horror

![](images/MV5BODRlNWRhZWUtMzdlZC00ZDIyLWFhZjMtYTcxNjI1ZDIwODhjXkEyXkFqcGc@._V1_.jpg){.absolute top="200" left="0" width="400"}

![](images/MV5BNTM2YWZhMDUtMzEzMi00YzUzLWI0ZjYtNzgzNTA4YWEzOTdkXkEyXkFqcGc@._V1_.jpg){.absolute top="50" right="50" width="400"}

![](images/best-classic-horror-movies-031124-e12e5ec5181a4e8091dde2bb201a8eec.jpg){.absolute bottom="0" right="50" width="400"}

## Netflix Horror Movies

```{r, warning=FALSE, message=FALSE, echo=FALSE}
library(RTextTools) 
library(tidyverse)
library(tidytuesdayR)
netflix <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv')
horror_subgenre <- netflix %>%
  filter(str_detect(listed_in, "Horror"), type == "Movie") %>%
  mutate(listed_in = str_remove(listed_in, ", International Movies")) %>%
  mutate(listed_in = str_remove(listed_in, ", Independent Movies")) %>%
  mutate(listed_in = str_remove_all(listed_in, "[,]")) %>%
  mutate(listed_in = str_remove_all(listed_in, "Movies")) %>%
  mutate(listed_in = str_replace(listed_in, "[:space:]&[:space:]", "&")) %>%
  group_by(listed_in) %>%
  summarize(num = n()) %>%
  arrange(desc(num)) %>%
  mutate(listed_in = str_remove(listed_in, "Horror"))
num_thrillers <- horror_subgenre %>%
  group_by(str_detect(listed_in,"Thrillers")) %>%
  summarize(num = sum(num)) %>%
  rename(Thrillers = 'str_detect(listed_in, \"Thrillers\")') %>%
  filter(Thrillers == TRUE) %>%
  mutate(genre = "Thrillers") %>%
  select(-Thrillers)
num_comedies <- horror_subgenre %>%
  group_by(str_detect(listed_in,"Comedies")) %>%
  summarize(num = sum(num)) %>%
  rename(Comedies = 'str_detect(listed_in, \"Comedies\")') %>%
  filter(Comedies == TRUE) %>%
  mutate(genre = "Comedies") %>%
  select(-Comedies)
num_action_adventure <- horror_subgenre %>%
  group_by(str_detect(listed_in,"Action/Adventure"))%>%
  summarize(num = sum(num)) %>%
  rename(Action_Adventure = 'str_detect(listed_in, \"Action/Adventure\")') %>%
  filter(Action_Adventure == TRUE) %>%
  mutate(genre = "Action&Adventure") %>%
  select(-Action_Adventure)
num_scifi_fantasy <- horror_subgenre %>%
  group_by(str_detect(listed_in,"Sci-Fi&Fantasy")) %>%
  summarize(num = sum(num)) %>%
  rename(SciFi_Fantasy = 'str_detect(listed_in, \"Sci-Fi&Fantasy\")') %>%
  filter(SciFi_Fantasy == TRUE) %>%
  mutate(genre = "SciFi&Fantasy") %>%
  select(-SciFi_Fantasy)
num_cult <- horror_subgenre %>%
  group_by(str_detect(listed_in,"Cult")) %>%
  summarize(num = sum(num)) %>%
  rename(Cult = 'str_detect(listed_in, \"Cult\")') %>%
  filter(Cult == TRUE) %>%
  mutate(genre = "Cult") %>%
  select(-Cult)
num_documentaries <- horror_subgenre %>%
  group_by(str_detect(listed_in,"Documentaries")) %>%
  summarize(num = sum(num)) %>%
  rename(Documentaries = 'str_detect(listed_in, \"Documentaries\")') %>%
  filter(Documentaries == TRUE)%>%
  mutate(genre = "Documentaties") %>%
  select(-Documentaries)
num_romantic <- horror_subgenre %>%
  group_by(str_detect(listed_in,"Romantic")) %>%
  summarize(num = sum(num)) %>%
  rename(Romantic = 'str_detect(listed_in, \"Romantic\")') %>%
  filter(Romantic == TRUE) %>%
  mutate(genre = "Romantic") %>%
  select(-Romantic)
num_horror <- horror_subgenre %>%
  filter(listed_in == " ") %>%
  mutate(listed_in = "Horror") %>%
  rename(genre = listed_in)
horror_df <- rbind(num_thrillers, num_comedies, num_action_adventure, num_scifi_fantasy, num_cult, num_documentaries, num_romantic, num_horror ) %>%
  as.data.frame() %>%
  arrange(desc(num))
```

```{r}
horror_df
```

## Netflix Horror Movies

```{r, echo=FALSE}
ggplot(horror_df, aes(x = genre, y = num)) +
  geom_bar(stat = "identity", aes(fill = genre)) + labs(
    title = "Subgenres among netflix horror movies",
    x = "Subgenre of horror movie",
    y = "Count"
  ) + 
  scale_x_discrete(guide = guide_axis(n.dodge=3)) +
  guides(fill=guide_legend(title="Subgenres"))
```

## Beta vs Normal Distribution

```{r echo=FALSE}
x <- seq(0,1,.001)
norm_y <- dnorm(x,.5,.05)
beta_y <- dbeta(x,50,50)
norm <- tibble(x,norm_y)
beta <- tibble(x,beta_y)

ggplot(norm, aes(x = x, y = norm_y)) +
  geom_point() +
  labs(
    title = "Example Normal Distribution"
  )

ggplot(beta, aes(x = x, y = beta_y)) +
  geom_point() +
  labs(
    title = "Example Beta Distribution"
  )

```

## Function 1: PI Interval Calculation

```{r}
PI <- function(data, coverage_prob){ 
  #Generates a normal prediction interval with an intended coverage probability of coverage_prob based on a vector of numeric data
  n <- length(data)
  lower_tscore <- qt((1-coverage_prob)/2, df = n - 1)
  upper_tscore <- qt(((1-coverage_prob)/2) + coverage_prob, df = n - 1)
  avg <- mean(data)
  stan_d <- sd(data)
  lower_bound <- avg + lower_tscore*stan_d * sqrt(1 + (1/n))
  upper_bound <- avg + upper_tscore*stan_d * sqrt(1 + (1/n))
  return(data.frame(PI_percentage = coverage_prob, lower = lower_bound, upper = upper_bound))
}

```

## Function 2: One simulation of beta-generated data

```{r}
one_beta_simulation <- function(n, alpha, beta, pi_prop){
  #Assesses prediction accuracy and actual coverage probability of a normal prediction interval when used on a vector of numeric data of size n. The numeric data is generated from a beta distribution with parameters alpha and beta.
  
  cover_df <- PI(rbeta(n, alpha, beta), pi_prop)
  
  cover_prop <- pbeta(cover_df[1, "upper"], alpha, beta) - pbeta(cover_df[1, "lower"], alpha, beta) #this is the proportion of the data's parent distribution that is actually covered by the normal prediction interval generated for said data.
  
  mean_in_interval <- .5 >= cover_df[1, "lower"] & .5 <= cover_df[1,"upper"]
  param_df <- data.frame(cover = cover_prop, alpha = rep(alpha, nrow(cover_df)), beta = rep(beta, nrow(cover_df)), mean_in_interval = mean_in_interval)
  df <- cbind(cover_df, param_df)
  return(df)
}

```

## Function 3: Multiple Beta simulations

```{r}
beta_sims_n <- function(n){
  #Iterates over a vector of possible alpha = beta values and applies one_beta_simulation to each possible value of alpha/beta. All simulations use data of sample size n.
  df1 <- map(parameters,\(param) one_beta_simulation(n, param, param, pi) ) %>%
  list_rbind()
  df2 <- data.frame(n = rep(n, nrow(df1)))
  df <- cbind(df2, df1)
  return(df)
}
```

## Simulations

```{r echo=FALSE}
PI <- function(data, coverage_prob){ 
  #Generates a normal prediction interval with an intended coverage probability of coverage_prob based on a vector of numeric data
  n <- length(data)
  lower_tscore <- qt((1-coverage_prob)/2, df = n - 1)
  upper_tscore <- qt(((1-coverage_prob)/2) + coverage_prob, df = n - 1)
  avg <- mean(data)
  stan_d <- sd(data)
  lower_bound <- avg + lower_tscore*stan_d * sqrt(1 + (1/n))
  upper_bound <- avg + upper_tscore*stan_d * sqrt(1 + (1/n))
  return(data.frame(PI_percentage = coverage_prob, lower = lower_bound, upper = upper_bound))
}

one_beta_simulation <- function(n, alpha, beta, pi_prop){
  #Assesses prediction accuracy and actual coverage probability of a normal prediction interval when used on a vector of numeric data of size n. The numeric data is generated from a beta distribution with parameters alpha and beta.
  
  cover_df <- PI(rbeta(n, alpha, beta), pi_prop)
  
  cover_prop <- pbeta(cover_df[1, "upper"], alpha, beta) - pbeta(cover_df[1, "lower"], alpha, beta) #this is the proportion of the data's parent distribution that is actually covered by the normal prediction interval generated for said data.
  
  mean_in_interval <- .5 >= cover_df[1, "lower"] & .5 <= cover_df[1,"upper"]
  param_df <- data.frame(cover = cover_prop, alpha = rep(alpha, nrow(cover_df)), beta = rep(beta, nrow(cover_df)), mean_in_interval = mean_in_interval)
  df <- cbind(cover_df, param_df)
  return(df)
}

beta_sims_n <- function(n){
  #Iterates over a vector of possible alpha = beta values and applies one_beta_simulation to each possible value of alpha/beta. All simulations use data of sample size n.
  df1 <- map(parameters,\(param) one_beta_simulation(n, param, param, pi) ) %>%
  list_rbind()
  df2 <- data.frame(n = rep(n, nrow(df1)))
  df <- cbind(df2, df1)
  return(df)
}

parameters <- seq(5, 200, by = 2)
n <- 2:500
ci <- .95

beta_df <- map(n, \(n) beta_sims_n(n)) %>%
  list_rbind()

rows <- sample(1:nrow(beta_df), 10)
map(rows, \(i) beta_df[i,]) %>%
  list_rbind()
```

## Results

```{r, echo=FALSE}
n_means_df <- beta_df %>%
  mutate(diff = cover - PI_percentage) %>%
  group_by(n) %>%
  summarize(mean = mean(diff), mu_in_interval = sum(mean_in_interval)/n()) %>%
  filter(n %in% 1:100)

ggplot(n_means_df, aes(x = n, y = mean)) + 
  geom_point() + 
  geom_hline(yintercept = 0, col = "black")  +
  labs(
    x = "sample size",
    y = "difference between actual and intended coverage",
    title = "Figure 1",
    subtitle = "difference between actual and intended coverage probability based on sample size",
  )
```

# FIN