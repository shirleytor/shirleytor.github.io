[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "shirleytor.github.io",
    "section": "",
    "text": "Hello there! Welcome to my website!\nI’m Shirley Toribio, a statistics student at Pomona College. My interests include machine learning, biostatistics, and topological data analysis. Feel free to look around my website!\n\n\n\nArt by me\n\n\nThis is a link to the github repository hosting this website: https://github.com/shirleytor/shirleytor.github.io"
  },
  {
    "objectID": "data_viz.html",
    "href": "data_viz.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Data source here."
  },
  {
    "objectID": "data_viz.html#analyzing-data-on-world-fairs-from-1855-to-2022",
    "href": "data_viz.html#analyzing-data-on-world-fairs-from-1855-to-2022",
    "title": "Data Visualization",
    "section": "",
    "text": "Data source here."
  },
  {
    "objectID": "data_viz.html#total-carbon-dioxide-emissions-from-major-natural-resource-companies",
    "href": "data_viz.html#total-carbon-dioxide-emissions-from-major-natural-resource-companies",
    "title": "Data Visualization",
    "section": "Total carbon dioxide emissions from major natural resource companies",
    "text": "Total carbon dioxide emissions from major natural resource companies\n\n\n\n\n\n\n\n\n\nData source here."
  },
  {
    "objectID": "project3_ds.html",
    "href": "project3_ds.html",
    "title": "Simulation Study",
    "section": "",
    "text": "Symmetric beta distributions and normal distributions are very similar to each other in shape. Due to this, in this project I examine how a 95% prediction interval that assumes data originates from a normal distribution would fare in terms of prediction accuracy and actual coverage probability of beta-distributed data. I define a confidence interval with “good” prediction accuracy as one that covers the actual mean of the data’s parent distribution, and a confidence interval with good coverage probability as one that covers approximately .95 of the beta distribution. All data is generated from beta distributions with mean .5."
  },
  {
    "objectID": "project3_ds.html#introduction",
    "href": "project3_ds.html#introduction",
    "title": "Simulation Study",
    "section": "",
    "text": "Symmetric beta distributions and normal distributions are very similar to each other in shape. Due to this, in this project I examine how a 95% prediction interval that assumes data originates from a normal distribution would fare in terms of prediction accuracy and actual coverage probability of beta-distributed data. I define a confidence interval with “good” prediction accuracy as one that covers the actual mean of the data’s parent distribution, and a confidence interval with good coverage probability as one that covers approximately .95 of the beta distribution. All data is generated from beta distributions with mean .5."
  },
  {
    "objectID": "project3_ds.html#simulations",
    "href": "project3_ds.html#simulations",
    "title": "Simulation Study",
    "section": "Simulations",
    "text": "Simulations\nFirst, I tidy up.\n\nlibrary(tidyverse)\n\nThen, I define a few functions that will help me in my task.\n\nCI &lt;- function(data, coverage_prob){ \n  #Generates a normal prediction interval with an intended coverage probability of coverage_prob based on a vector of numeric data\n  \n  lower_zscore &lt;- qnorm((1-coverage_prob)/2)\n  upper_zscore &lt;- qnorm(((1-coverage_prob)/2) + coverage_prob)\n  avg &lt;- mean(data)\n  stan_d &lt;- sd(data)\n  lower_bound &lt;- avg + lower_zscore*stan_d\n  upper_bound &lt;- avg + upper_zscore*stan_d\n  return(data.frame(PI_percentage = coverage_prob, lower = lower_bound, upper = upper_bound))\n}\n\none_beta_simulation &lt;- function(n, alpha, beta, ci_prop){\n  #Assesses prediction accuracy and actual coverage probability of a normal prediction interval when used on a vector of numeric data of size n. The numeric data is generated from a beta distribution with parameters alpha and beta.\n  \n  cover_df &lt;- CI(rbeta(n, alpha, beta), ci_prop)\n  cover_prop &lt;- pbeta(cover_df[1, \"upper\"], alpha, beta) - pbeta(cover_df[1, \"lower\"], alpha, beta)\n  mean_in_interval &lt;- .5 &gt;= cover_df[1, \"lower\"] & .5 &lt;= cover_df[1,\"upper\"]\n  param_df &lt;- data.frame(cover = cover_prop, alpha = rep(alpha, nrow(cover_df)), beta = rep(beta, nrow(cover_df)), mean_in_interval = mean_in_interval)\n  df &lt;- cbind(cover_df, param_df)\n  return(df)\n}\n\nbeta_sims_n &lt;- function(n){\n  #Iterates over a vector of possible alpha = beta values and applies one_beta_simulation to each possible value of alpha/beta. All simulations use data of sample size n.\n  df1 &lt;- map(parameters,\\(param) one_beta_simulation(n, param, param, ci) ) %&gt;%\n  list_rbind()\n  df2 &lt;- data.frame(n = rep(n, nrow(df1)))\n  df &lt;- cbind(df2, df1)\n  return(df)\n}\n\nTime to simulate over different parameter values and sample sizes!\n\nparameters &lt;- seq(5, 200, by = 2)\nn &lt;- 2:500\nci &lt;- .95\n\nbeta_df &lt;- map(n, \\(n) beta_sims_n(n)) %&gt;%\n  list_rbind()\n\nThis is a glimpse at the results of the simulations.\n\nrows &lt;- sample(1:nrow(beta_df), 10)\nmap(rows, \\(i) beta_df[i,]) %&gt;%\n  list_rbind()\n\n     n PI_percentage     lower     upper     cover alpha beta mean_in_interval\n1  247          0.95 0.4523062 0.5547580 0.9355907   165  165             TRUE\n2   83          0.95 0.4359215 0.5669415 0.9650810   129  129             TRUE\n3  170          0.95 0.4418966 0.5511343 0.9487325   161  161             TRUE\n4  350          0.95 0.4462158 0.5532432 0.9619462   187  187             TRUE\n5  135          0.95 0.4451088 0.5587557 0.9621922   167  167             TRUE\n6  415          0.95 0.4475184 0.5524290 0.9621266   195  195             TRUE\n7  331          0.95 0.4430825 0.5614637 0.9531166   141  141             TRUE\n8  471          0.95 0.4038219 0.6013108 0.9345494    43   43             TRUE\n9  199          0.95 0.4199542 0.5844024 0.9165128    55   55             TRUE\n10 348          0.95 0.4325954 0.5677737 0.9326805    91   91             TRUE\n\n\nThis is a random sample of rows from the actual dataset, which has 48902 rows and 8 columns. Each row corresponds to a simulated random sample of size n from a beta distribution with parameters alpha and beta. For each random sample, a normal prediction interval was generated with bounds “lower” and “upper”. “PI_percentage” refers to the intended coverage probability and “cover” refers to the actual coverage probability of said prediction interval over the beta distribution the data was generated from. “mean_in_interval” is a binary variable that states if the prediction interval covered the mean of the distribution."
  },
  {
    "objectID": "project3_ds.html#insights",
    "href": "project3_ds.html#insights",
    "title": "Simulation Study",
    "section": "Insights",
    "text": "Insights\n\nn_means_df &lt;- beta_df %&gt;%\n  mutate(diff = cover - PI_percentage) %&gt;%\n  group_by(n) %&gt;%\n  summarize(mean = mean(diff), mu_in_interval = sum(mean_in_interval)/n()) %&gt;%\n  filter(n %in% 1:100)\n\nggplot(n_means_df, aes(x = n, y = mean)) + \n  geom_point() + \n  geom_hline(yintercept = 0, col = \"black\")  +\n  labs(\n    x = \"sample size\",\n    y = \"difference between actual and intended coverage\",\n    title = \"Figure 1\",\n    subtitle = \"difference between actual and intended coverage probability based on sample size\",\n  )\n\n\n\n\n\n\n\n\nFigure 1 graphs the mean difference between the actual coverage probability and intended coverage probability (calculated as: actual coverage probability - intended coverage probability) per each sample size from 2 to 100. A negative mean difference indicates the actual coverage probability tended to be less than the intended coverage probability, which is undesirable. For sample sizes from 2 to around 13, the mean differences tend to be much lower than 0, meaning the prediction interval is likely to cover less than intended. As the sample size increases, this mean difference seems to converge in probability to 0, meaning the actual coverage probability is more likely to match the intended coverage probability.\nFor small sample sizes it seems likely a normal prediction interval will cover less than intended, with it seeming to cover less the smaller the sample size is.\n\nn_means_df &lt;- beta_df %&gt;%\n  mutate(diff = cover - PI_percentage) %&gt;%\n  group_by(n) %&gt;%\n  summarize(mean = mean(diff), mu_in_interval = sum(mean_in_interval)/n()) %&gt;%\n  filter(n %in% 1:30)\n\nggplot(n_means_df, aes(x = n, y = mu_in_interval)) + \n  geom_point()  +\n  labs(\n    x = \"sample size\",\n    y = \"proportion of mu-inclusive prediction intervals\",\n    title = \"Figure 2\",\n    subtitle = \"proportion of mu-inclusive prediction intervals based on sample size\"\n  )\n\n\n\n\n\n\n\n\nFigure 2 plots the proportion of prediction intervals that cover mu = .5 per each sample size from 2 to 30. These points converge to 1 at a sample size of around 10, meaning for sample sizes of 10 or greater it is probable that all random samples with those samples sizes will produce normal-prediction intervals that cover the mean of the beta distribution said data originated from. Based on this plot, the normal-prediction interval fares well with accepting the null hypothesis of mu = .5 given the null distribution is symmetric and beta.\n\nns_of_interest &lt;- c(5, 10, 30, 50, 100, 500)\nbeta_df_2 &lt;- filter(beta_df,n %in% ns_of_interest) %&gt;%\n  mutate(sample_size = as.factor(n))\nggplot(beta_df_2, aes(x = alpha, y = cover, color = sample_size)) +\n  geom_point() +\n  geom_smooth(aes(line = n ), se = FALSE) +\n  labs(\n    x = \"value of alpha and beta\",\n    y = \"actual coverage probability\",\n    title = \"Figure 3\",\n    subtitle = \"actual coverage probability based on parameter values\"\n  )\n\n\n\n\n\n\n\n\nFigure 3 plots the actual coverage probability per each value of alpha and beta. Points and lines are colored based on sample size, which are described in the legend. Alpha and beta have the same values, by the way. All the lines of best fit seem close to being horizontal, meaning that there most likely is not a relationship between the values of alpha/beta and the actual coverage probability of the data. Based on the y-intercepts of each line and the vertical spread of points given sample size, normal prediction intervals based on small amounts of data seem more likely to deviate from the intended coverage probability of the data’s parent symmetric beta distribution and to deviate to being lower than .95."
  },
  {
    "objectID": "project3_ds.html#conclusion",
    "href": "project3_ds.html#conclusion",
    "title": "Simulation Study",
    "section": "Conclusion",
    "text": "Conclusion\nBy generating data from symmetric beta distributions with mu = .5 and making normal prediction intervals based on this data, I was able to assess the predictive accuracy and actual coverage probability of normal prediction intervals when applied to symmetric-beta data. Even for sample sizes as small as 10, normal prediction intervals seem to have good predictive accuracy, although their coverage probability is quite poor for sample sizes below 30. When the null hypothesis is mu = .5, it appears they are quite adept at avoiding type I errors."
  },
  {
    "objectID": "proj4.html",
    "href": "proj4.html",
    "title": "SQL",
    "section": "",
    "text": "I plan to query data from the Wideband Acoustic Immittance Database, which is a repository of auditory measurements from different people. From this data, two graphs will be generated. One graph will replicate Figure 1 from Voss(2020) and the other will compare mean absorbance measurements between people of different sexes over different frequencies.\n\nlibrary(RMariaDB)\nlibrary(dbplyr)\nlibrary(dplyr)\nlibrary(tidyverse)\n\n\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n #collect(Measurements)\n\nYou can add options to executable code like this\n\nSELECT Measurements.Identifier,\n       Measurements.Frequency,\n       AVG(Absorbance) AS mean_absorbance,\n       PI_Info.AuthorsShortList AS authors\nFROM Measurements\nJOIN PI_Info ON Measurements.Identifier = PI_Info.Identifier\nGROUP BY Measurements.Identifier, Measurements.Frequency;\n\n\ntable1 %&gt;%\n  filter(authors %in% c(\"Abur et al.\", \"Feeney et al.\", \"Groon et al.\", \"Lewis and Neely\", \"Liu et al.\", \"Rosowski et al.\", \"Shahnaz et al.\", \"Shaver and Sun\", \"Sun et al.\", \"Voss and Allen\", \"Voss et al.\", \"Werner et al.\")) %&gt;%\n  ggplot(aes(x = Frequency, y = mean_absorbance)) +\n  geom_smooth(aes(color = authors), se = FALSE) +\n  xlim(0, 8000)\n\n\n\n\n\n\n\n\nThe echo: false option disables the printing of code (only output is displayed).\n\nSELECT\n  Subjects.Sex AS sex,\n  Subjects.Race AS race,\n  Subjects.Ethnicity AS ethnicity,\n  Subjects.Identifier,\n  Measurements.Identifier,\n  Measurements.Frequency AS freq,\n  AVG(Measurements.Absorbance) AS mean_absorbance\nFROM Subjects\nJOIN Measurements ON Subjects.SubjectNumber = Measurements.SubjectNumber \nWHERE Subjects.Identifier = \"Aithal_2013\" AND Measurements.Identifier = \"Aithal_2013\"\nGROUP BY ethnicity, race, sex, freq;\n\n\ntable2 &lt;- table2[,-c(4)]\ntable2 %&gt;%\n  ggplot(aes(x = freq, y = mean_absorbance, color = sex)) +\n  geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\nUsing SQL queries, I filtered through and sorted data in a manner that allowed me to compare absorbance measurements across sexes and copy figure 1 of Voss(2020). I did this with 2 SQL queries and joined different tables from the same database to produce both graphs. Following each query, I used ggplot to plot mean absorbance measurements alongside frequency."
  },
  {
    "objectID": "SQL_Proj.html",
    "href": "SQL_Proj.html",
    "title": "Wideband Acoustic Immittance Data Visualization",
    "section": "",
    "text": "I plan to query data from the Wideband Acoustic Immittance Database, which is a repository of auditory measurements from different people. From this data, two graphs will be generated. One graph will replicate Figure 1 from Voss(2020) and the other will compare mean absorbance measurements between people of different sexes over different frequencies.\n\nlibrary(RMariaDB)\nlibrary(dbplyr)\nlibrary(dplyr)\nlibrary(tidyverse)\n\n\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n #collect(Measurements)\n\n\nSELECT Measurements.Identifier,\n       Measurements.Frequency,\n       AVG(Absorbance) AS mean_absorbance,\n       CONCAT(PI_Info.AuthorsShortList,\" (\", PI_Info.Year, \")\",\" N=\", COUNT(DISTINCT Measurements.SubjectNumber) ,\"; \",Measurements.Instrument) AS studies\nFROM Measurements\nJOIN PI_Info ON Measurements.Identifier = PI_Info.Identifier\nWHERE PI_Info.AuthorsShortList IN (\"Abur et al.\", \"Feeney et al.\", \"Groon et al.\", \"Lewis and Neely\", \"Liu et al.\", \"Rosowski et al.\", \"Shahnaz et al.\", \"Shaver and Sun\", \"Sun et al.\", \"Voss and Allen\", \"Voss et al.\", \"Werner et al.\") AND Measurements.Frequency BETWEEN 0 and 8000\nGROUP BY Measurements.Identifier, Measurements.Frequency,  Measurements.Instrument;\n\n\ntable1 %&gt;%\n  ggplot(aes(x = Frequency, y = mean_absorbance)) +\n  geom_line(aes(color = studies), se = FALSE)\n\n\n\n\n\n\n\n\n\nSELECT\n  Subjects.Sex AS sex,\n  Subjects.Race AS race,\n  Subjects.Ethnicity AS ethnicity,\n  Subjects.Identifier,\n  Measurements.Frequency AS freq,\n  AVG(Measurements.Absorbance) AS mean_absorbance\nFROM Subjects\nJOIN Measurements ON Subjects.SubjectNumber = Measurements.SubjectNumber \nWHERE Subjects.Identifier = \"Aithal_2013\" AND Measurements.Identifier = \"Aithal_2013\"\nGROUP BY ethnicity, race, sex, freq;\n\n\ntable2 %&gt;%\n  ggplot(aes(x = freq, y = mean_absorbance, color = sex)) +\n  geom_line(se = FALSE)\n\n\n\n\n\n\n\n\nUsing SQL queries, I filtered through and sorted data in a manner that allowed me to compare absorbance measurements across sexes and copy figure 1 of Voss(2020). I did this with 2 SQL queries and joined different tables from the same database to produce both graphs. Following each query, I used ggplot to plot mean absorbance measurements alongside frequency."
  },
  {
    "objectID": "Project 2/Netflix_Analysis.html",
    "href": "Project 2/Netflix_Analysis.html",
    "title": "Analysis of Netflix Horror Movies and TV Shows",
    "section": "",
    "text": "library(RTextTools) \nlibrary(tidyverse)\nlibrary(tidytuesdayR)\nnetflix &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv')"
  },
  {
    "objectID": "Project 2/Netflix_Analysis.html#netflix-horror-movies",
    "href": "Project 2/Netflix_Analysis.html#netflix-horror-movies",
    "title": "Analysis of Netflix Horror Movies and TV Shows",
    "section": "Netflix Horror Movies",
    "text": "Netflix Horror Movies\n\nhorror_subgenre &lt;- netflix %&gt;%\n  filter(str_detect(listed_in, \"Horror\"), type == \"Movie\") %&gt;%\n  mutate(listed_in = str_remove(listed_in, \", International Movies\")) %&gt;%\n  mutate(listed_in = str_remove(listed_in, \", Independent Movies\")) %&gt;%\n  mutate(listed_in = str_remove_all(listed_in, \"[,]\")) %&gt;%\n  mutate(listed_in = str_remove_all(listed_in, \"Movies\")) %&gt;%\n  mutate(listed_in = str_replace(listed_in, \"[:space:]&[:space:]\", \"&\")) %&gt;%\n  group_by(listed_in) %&gt;%\n  summarize(num = n()) %&gt;%\n  arrange(desc(num)) %&gt;%\n  mutate(listed_in = str_remove(listed_in, \"Horror\"))\n\n\nnum_thrillers &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Thrillers\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Thrillers = 'str_detect(listed_in, \\\"Thrillers\\\")') %&gt;%\n  filter(Thrillers == TRUE) %&gt;%\n  mutate(genre = \"Thrillers\") %&gt;%\n  select(-Thrillers)\n\nnum_comedies &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Comedies\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Comedies = 'str_detect(listed_in, \\\"Comedies\\\")') %&gt;%\n  filter(Comedies == TRUE) %&gt;%\n  mutate(genre = \"Comedies\") %&gt;%\n  select(-Comedies)\n\n\nnum_action_adventure &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Action/Adventure\"))%&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Action_Adventure = 'str_detect(listed_in, \\\"Action/Adventure\\\")') %&gt;%\n  filter(Action_Adventure == TRUE) %&gt;%\n  mutate(genre = \"Action&Adventure\") %&gt;%\n  select(-Action_Adventure)\n\nnum_scifi_fantasy &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Sci-Fi&Fantasy\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(SciFi_Fantasy = 'str_detect(listed_in, \\\"Sci-Fi&Fantasy\\\")') %&gt;%\n  filter(SciFi_Fantasy == TRUE) %&gt;%\n  mutate(genre = \"SciFi&Fantasy\") %&gt;%\n  select(-SciFi_Fantasy)\n\nnum_cult &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Cult\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Cult = 'str_detect(listed_in, \\\"Cult\\\")') %&gt;%\n  filter(Cult == TRUE) %&gt;%\n  mutate(genre = \"Cult\") %&gt;%\n  select(-Cult)\n\nnum_documentaries &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Documentaries\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Documentaries = 'str_detect(listed_in, \\\"Documentaries\\\")') %&gt;%\n  filter(Documentaries == TRUE)%&gt;%\n  mutate(genre = \"Documentaties\") %&gt;%\n  select(-Documentaries)\n\nnum_romantic &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Romantic\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Romantic = 'str_detect(listed_in, \\\"Romantic\\\")') %&gt;%\n  filter(Romantic == TRUE) %&gt;%\n  mutate(genre = \"Romantic\") %&gt;%\n  select(-Romantic)\n\nnum_horror &lt;- horror_subgenre %&gt;%\n  filter(listed_in == \" \") %&gt;%\n  mutate(listed_in = \"horror\") %&gt;%\n  rename(genre = listed_in)\n\nhorror_df &lt;- rbind(num_thrillers, num_comedies, num_action_adventure, num_scifi_fantasy, num_cult, num_documentaries, num_romantic, num_horror ) %&gt;%\n  as.data.frame() %&gt;%\n  arrange(desc(num))\nhorror_df\n\n  num         genre\n1 125        horror\n2 110     Thrillers\n3  38      Comedies\n4  19 SciFi&Fantasy\n5  12          Cult\n6   2 Documentaties\n7   2      Romantic\n\n\n\nggplot(horror_df, aes(x = genre, y = num)) +\n  geom_bar(stat = \"identity\", aes(fill = genre)) + labs(\n    title = \"Subgenres among netflix horror movies\",\n    x = \"Subgenre of horror movie\",\n    y = \"Count\"\n  ) + \n  scale_x_discrete(guide = guide_axis(n.dodge=3)) +\n  guides(fill=guide_legend(title=\"Subgenres\"))\n\n\n\n\n\n\n\n\nBased on this plot of the number of horror movies with specific subgenres, it seems most netflix horror movies either do not have a subgenre or have thriller as their subgenre. Other subgenres appear substantially less present among Netflix horror movies."
  },
  {
    "objectID": "Project 2/Netflix_Analysis.html#netflix-tv-shows",
    "href": "Project 2/Netflix_Analysis.html#netflix-tv-shows",
    "title": "Analysis of Netflix Horror Movies and TV Shows",
    "section": "Netflix TV Shows",
    "text": "Netflix TV Shows\n\ndata &lt;- netflix %&gt;% \n  filter(type == \"TV Show\") %&gt;%\n  mutate(num_seasons = as.numeric(str_extract(duration, \"\\\\d+\" )))\n\nggplot(data, aes(x = release_year, y = num_seasons)) +\n  geom_point() +\n  xlim(1970,2025)+\n  geom_smooth(se = FALSE) + \n  labs(\n    title = \"Relationship between release year and number of seasons of netflix tv show\",\n    x = \"Release year\",\n    y = \"Number of seasons\"\n  )\n\n\n\n\n\n\n\n\nBased on this plot, the number of seasons that a Netflix show has tends to be lower for shows released between 2005 and 2020 than for other shows. Due to the discreteness of values on the x-axis, multiple points are most likely overlapping. This explains why it appears the right side of the graph has less points below the line of best fit than above it even with the line trending downwards.\nData source: https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv"
  },
  {
    "objectID": "Beta_Simulation.html",
    "href": "Beta_Simulation.html",
    "title": "Simulation",
    "section": "",
    "text": "Symmetric beta distributions and normal distributions are very similar to each other in shape. Due to this, in this project I examine how a 95% prediction interval that assumes data originates from a normal distribution would fare in terms of prediction accuracy and actual coverage probability of beta-distributed data. I define a prediction interval with “good” prediction accuracy as one that covers the actual mean of the data’s parent distribution, and a prediction interval with good coverage probability as one that covers approximately .95 of the beta distribution. All data is generated from beta distributions with mean .5."
  },
  {
    "objectID": "Beta_Simulation.html#introduction",
    "href": "Beta_Simulation.html#introduction",
    "title": "Simulation",
    "section": "",
    "text": "Symmetric beta distributions and normal distributions are very similar to each other in shape. Due to this, in this project I examine how a 95% prediction interval that assumes data originates from a normal distribution would fare in terms of prediction accuracy and actual coverage probability of beta-distributed data. I define a prediction interval with “good” prediction accuracy as one that covers the actual mean of the data’s parent distribution, and a prediction interval with good coverage probability as one that covers approximately .95 of the beta distribution. All data is generated from beta distributions with mean .5."
  },
  {
    "objectID": "Beta_Simulation.html#simulations",
    "href": "Beta_Simulation.html#simulations",
    "title": "Simulation",
    "section": "Simulations",
    "text": "Simulations\nFirst, I tidy up.\n\nlibrary(tidyverse)\n\nThen, I define a few functions that will help me in my task.\n\nPI &lt;- function(data, coverage_prob){ \n  #Generates a normal prediction interval with an intended coverage probability of coverage_prob based on a vector of numeric data\n  n &lt;- length(data)\n  lower_tscore &lt;- qt((1-coverage_prob)/2, df = n - 1)\n  upper_tscore &lt;- qt(((1-coverage_prob)/2) + coverage_prob, df = n - 1)\n  avg &lt;- mean(data)\n  stan_d &lt;- sd(data)\n  lower_bound &lt;- avg + lower_tscore*stan_d * sqrt(1 + (1/n))\n  upper_bound &lt;- avg + upper_tscore*stan_d * sqrt(1 + (1/n))\n  return(data.frame(PI_percentage = coverage_prob, lower = lower_bound, upper = upper_bound))\n}\n\nPI is a function that takes a vector of numeric data and produces a high-density prediction interval intended to cover the proportion of said data’s parent distribution, which is given by coverage_prob. This prediction interval is created under the assumption that the data is normally distributed (although we know it is not). Let \\(s\\) be the sample standard deviation of our data, \\(n\\) be the size of our sample, \\(\\hat{p}\\) be the mean of our data, and \\(t_{p,n-1}\\) be the quantile value associated with the highest density coverage probability \\(p\\) in a \\(t\\) distribution with \\(n-1\\) degrees of freedom. If we assume that our data is normal, then the highest density prediction interval with coverage probability \\(p\\) is best predicted as\n\\[\\hat{p} \\pm t_{p,n-1}*s*\\sqrt{1+\\frac{1}{n}}\\] PI uses this formula to generate the bounds of its prediction interval.\n\none_beta_simulation &lt;- function(n, alpha, beta, pi_prop){\n  #Assesses prediction accuracy and actual coverage probability of a normal prediction interval when used on a vector of numeric data of size n. The numeric data is generated from a beta distribution with parameters alpha and beta.\n  \n  cover_df &lt;- PI(rbeta(n, alpha, beta), pi_prop)\n  \n  cover_prop &lt;- pbeta(cover_df[1, \"upper\"], alpha, beta) - pbeta(cover_df[1, \"lower\"], alpha, beta) #this is the proportion of the data's parent distribution that is actually covered by the normal prediction interval generated for said data.\n  \n  mean_in_interval &lt;- .5 &gt;= cover_df[1, \"lower\"] & .5 &lt;= cover_df[1,\"upper\"]\n  param_df &lt;- data.frame(cover = cover_prop, alpha = rep(alpha, nrow(cover_df)), beta = rep(beta, nrow(cover_df)), mean_in_interval = mean_in_interval)\n  df &lt;- cbind(cover_df, param_df)\n  return(df)\n}\n\none_beta_simulation randomly samples \\(n\\) data points from a beta distribution with parameters alpha and beta and calculates a normal prediction interval for said data using function PI. It then determines what proportion of the data’s parent beta distribution is covered by the prediction interval and checks if the mean of said distribution is covered by the prediction interval.\n\nbeta_sims_n &lt;- function(n){\n  #Iterates over a vector of possible alpha = beta values and applies one_beta_simulation to each possible value of alpha/beta. All simulations use data of sample size n.\n  df1 &lt;- map(parameters,\\(param) one_beta_simulation(n, param, param, pi) ) %&gt;%\n  list_rbind()\n  df2 &lt;- data.frame(n = rep(n, nrow(df1)))\n  df &lt;- cbind(df2, df1)\n  return(df)\n}\n\nbeta_sims_n maps over a vector of potential parameter values for a beta distribution with mean \\(.5\\) and uses one_beta_simulation per each iteration, with all iterations taking the same value for the data’s sample size. It randomly samples \\(n\\) points multiple times from different beta distribution with mean .5 and generates normal prediction intervals for each sample. It also determines the proportion of the each sample’s parent distribution that said intervals actually cover.\nTime to simulate over different parameter values and sample sizes!\n\nparameters &lt;- seq(5, 200, by = 2)\nn &lt;- 2:500\npi &lt;- .95\n\nbeta_df &lt;- map(n, \\(n) beta_sims_n(n)) %&gt;%\n  list_rbind()\n\nThis is a glimpse at the results of the simulations.\n\nrows &lt;- sample(1:nrow(beta_df), 10)\nmap(rows, \\(i) beta_df[i,]) %&gt;%\n  list_rbind()\n\n     n PI_percentage     lower     upper     cover alpha beta mean_in_interval\n1  296          0.95 0.4422516 0.5623847 0.9265642   111  111             TRUE\n2  238          0.95 0.4491614 0.5516994 0.9553338   191  191             TRUE\n3  299          0.95 0.4282970 0.5688020 0.9625248   109  109             TRUE\n4  183          0.95 0.4256824 0.5749415 0.9685752   103  103             TRUE\n5  289          0.95 0.4315870 0.5690621 0.9477599    99   99             TRUE\n6   98          0.95 0.4488861 0.5515989 0.9368242   163  163             TRUE\n7   67          0.95 0.3460886 0.6460942 0.9750596    27   27             TRUE\n8  428          0.95 0.4201242 0.5840119 0.9467051    69   69             TRUE\n9   65          0.95 0.4230077 0.5758414 0.9863587   129  129             TRUE\n10 156          0.95 0.4395677 0.5590688 0.9492623   133  133             TRUE\n\n\nThis is a random sample of rows from the actual dataset, which has 48902 rows and 8 columns. Each row corresponds to a simulated random sample of size n from a beta distribution with parameters alpha and beta. For each random sample, a normal prediction interval was generated with bounds “lower” and “upper”. “PI_percentage” refers to the intended coverage probability and “cover” refers to the actual coverage probability of said prediction interval over the beta distribution the data was generated from. “mean_in_interval” is a binary variable that states if the prediction interval covered the mean of the distribution."
  },
  {
    "objectID": "Beta_Simulation.html#insights",
    "href": "Beta_Simulation.html#insights",
    "title": "Simulation",
    "section": "Insights",
    "text": "Insights\n\nn_means_df &lt;- beta_df %&gt;%\n  mutate(diff = cover - PI_percentage) %&gt;%\n  group_by(n) %&gt;%\n  summarize(mean = mean(diff), mu_in_interval = sum(mean_in_interval)/n())\navg &lt;- mean(n_means_df$mean)\nggplot(n_means_df, aes(x = n, y = mean)) + \n  geom_point() + \n  geom_hline(yintercept = 0, col = \"black\")  +\n  geom_hline(yintercept = avg, col = \"red\")  +\n  labs(\n    x = \"sample size\",\n    y = \"difference between actual and intended coverage\",\n    title = \"Figure 1\",\n    subtitle = \"difference between actual and intended coverage probability based on sample size\",\n  )\n\n\n\n\n\n\n\nn_means_df &lt;- beta_df %&gt;%\n  mutate(diff = cover - PI_percentage) %&gt;%\n  group_by(n) %&gt;%\n  summarize(mean = mean(diff), mu_in_interval = sum(mean_in_interval)/n()) %&gt;%\n  filter(n %in% 1:100)\n\nggplot(n_means_df, aes(x = n, y = mean)) + \n  geom_point() + \n  geom_hline(yintercept = 0, col = \"black\")  +\n  geom_hline(yintercept = avg, col = \"red\")  +\n  labs(\n    x = \"sample size\",\n    y = \"difference between actual and intended coverage\",\n    title = \"Figure 1 close up\",\n    subtitle = \"difference between actual and intended coverage probability based on sample size\",\n  )\n\n\n\n\n\n\n\n\nFigure 1 graphs the mean difference between the actual coverage probability and intended coverage probability (calculated as: actual coverage probability - intended coverage probability) per each sample size from 2 to 10000. A negative mean difference indicates the actual coverage probability tended to be less than the intended coverage probability, which is undesirable, while a positive mean difference indicates the actual cover probability tended to be more than the intended coverage probability. The mean difference between actual and intended coverage probability seems to converge to a value a little bit above 0 as the sample size increases, indicating that actual coverage probability tends to be more than the intended coverage and that this is more so as sample size increases.\nFor small sample sizes the mean difference between actual and intended coverage probability has a lot more variance around 0 than it does for larger sample sizes, which can be attributed to sampling variability. Overall, absolute differences in actual coverage probability and intended coverage probability don’t appear to extend beyond .02, indicating normal prediction intervals tend to have good coverage probability for symmetric, beta distributed data.\n\nn_means_df &lt;- beta_df %&gt;%\n  mutate(diff = cover - PI_percentage) %&gt;%\n  group_by(n) %&gt;%\n  summarize(mean = mean(diff), mu_in_interval = sum(mean_in_interval)/n()) %&gt;%\n  filter(n %in% 1:30)\n\nggplot(n_means_df, aes(x = n, y = mu_in_interval)) + \n  geom_point()  +\n  labs(\n    x = \"sample size\",\n    y = \"proportion of mu-inclusive prediction intervals\",\n    title = \"Figure 2\",\n    subtitle = \"proportion of mu-inclusive prediction intervals based on sample size\"\n  )\n\n\n\n\n\n\n\n\nFigure 2 plots the proportion of prediction intervals that cover mu = .5 per each sample size from 2 to 30. These points converge to 1 at a sample size of around 4, meaning for sample sizes of 4 or greater it is probable that all random samples with those samples sizes will produce normal-prediction intervals that cover the mean of the beta distribution said data originated from.\n\nns_of_interest &lt;- c(5, 10, 30, 50, 100, 500)\nbeta_df_2 &lt;- filter(beta_df,n %in% ns_of_interest) %&gt;%\n  mutate(sample_size = as.factor(n))\nggplot(beta_df_2, aes(x = alpha, y = cover, color = sample_size)) +\n  geom_point() +\n  geom_smooth(aes(line = n ), se = FALSE) +\n  labs(\n    x = \"value of alpha and beta\",\n    y = \"actual coverage probability\",\n    title = \"Figure 3\",\n    subtitle = \"actual coverage probability based on parameter values\"\n  )\n\n\n\n\n\n\n\n\nFigure 3 plots the actual coverage probability per each value of alpha and beta. Points and lines are colored based on sample size, which are described in the legend. Alpha and beta have the same values, by the way. All the lines of best fit seem close to being horizontal, meaning that there most likely is not a relationship between the values of alpha/beta and the actual coverage probability of the data’s prediction interval. Based on the large overlap between lines, normal prediction intervals based on small amounts of data don’t seem more likely to deviate from the intended coverage probability of the data’s parent symmetric beta distribution, although they do have larger amounts of variability around their mean coverage probability."
  },
  {
    "objectID": "Beta_Simulation.html#conclusion",
    "href": "Beta_Simulation.html#conclusion",
    "title": "Simulation",
    "section": "Conclusion",
    "text": "Conclusion\nBy generating data from symmetric beta distributions with mu = .5 and making normal prediction intervals based on this data, I was able to assess the predictive accuracy and actual coverage probability of normal prediction intervals when applied to symmetric-beta data. Even given small sample sizes, normal prediction intervals seem to have good predictive accuracy and good coverage probability."
  },
  {
    "objectID": "Netflix_Analysis.html",
    "href": "Netflix_Analysis.html",
    "title": "Netflix Analysis",
    "section": "",
    "text": "library(RTextTools) \nlibrary(tidyverse)\nlibrary(tidytuesdayR)\nnetflix &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv')"
  },
  {
    "objectID": "Netflix_Analysis.html#netflix-horror-movies",
    "href": "Netflix_Analysis.html#netflix-horror-movies",
    "title": "Netflix Analysis",
    "section": "Netflix Horror Movies",
    "text": "Netflix Horror Movies\nIn this analysis of Netflix horror movies, I look at all movies with horror listed as a genre and see what other genres are also listed for said movies. I then create a bar plot comparing the number of other genres listed among Netflix horror movies.\nFirst I filter for movies with horror listed as one of its genres and clean the variable listing movie genres so that it only includes genres that aren’t horror. This is all saved in the “horror_subgenre” object.\n\nhorror_subgenre &lt;- netflix %&gt;%\n  filter(str_detect(listed_in, \"Horror\"), type == \"Movie\") %&gt;%\n  mutate(listed_in = str_remove(listed_in, \", International Movies\")) %&gt;%\n  mutate(listed_in = str_remove(listed_in, \", Independent Movies\")) %&gt;%\n  mutate(listed_in = str_remove_all(listed_in, \"[,]\")) %&gt;%\n  mutate(listed_in = str_remove_all(listed_in, \"Movies\")) %&gt;%\n  mutate(listed_in = str_replace(listed_in, \"[:space:]&[:space:]\", \"&\")) %&gt;%\n  group_by(listed_in) %&gt;%\n  summarize(num = n()) %&gt;%\n  arrange(desc(num)) %&gt;%\n  mutate(listed_in = str_remove(listed_in, \"Horror\"))\n\nThen I count the number of movies within “horror_subgenre” that list a specific secondary genre, with the secondary genres I consider being the following: thriller, comedy, romance, action/adventure, science fiction and fantasy, cult, documentary, and none. None means that the movie only has horror as its genre.\n\nnum_thrillers &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Thrillers\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Thrillers = 'str_detect(listed_in, \\\"Thrillers\\\")') %&gt;%\n  filter(Thrillers == TRUE) %&gt;%\n  mutate(genre = \"Thrillers\") %&gt;%\n  select(-Thrillers)\n\nnum_comedies &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Comedies\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Comedies = 'str_detect(listed_in, \\\"Comedies\\\")') %&gt;%\n  filter(Comedies == TRUE) %&gt;%\n  mutate(genre = \"Comedies\") %&gt;%\n  select(-Comedies)\n\n\nnum_action_adventure &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Action/Adventure\"))%&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Action_Adventure = 'str_detect(listed_in, \\\"Action/Adventure\\\")') %&gt;%\n  filter(Action_Adventure == TRUE) %&gt;%\n  mutate(genre = \"Action&Adventure\") %&gt;%\n  select(-Action_Adventure)\n\nnum_scifi_fantasy &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Sci-Fi&Fantasy\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(SciFi_Fantasy = 'str_detect(listed_in, \\\"Sci-Fi&Fantasy\\\")') %&gt;%\n  filter(SciFi_Fantasy == TRUE) %&gt;%\n  mutate(genre = \"SciFi&Fantasy\") %&gt;%\n  select(-SciFi_Fantasy)\n\nnum_cult &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Cult\")) %&gt;% \n  summarize(num = sum(num)) %&gt;%\n  rename(Cult = 'str_detect(listed_in, \\\"Cult\\\")') %&gt;%\n  filter(Cult == TRUE) %&gt;%\n  mutate(genre = \"Cult\") %&gt;%\n  select(-Cult)\n\nnum_documentaries &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Documentaries\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Documentaries = 'str_detect(listed_in, \\\"Documentaries\\\")') %&gt;%\n  filter(Documentaries == TRUE)%&gt;%\n  mutate(genre = \"Documentaties\") %&gt;%\n  select(-Documentaries)\n\nnum_romantic &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Romantic\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Romantic = 'str_detect(listed_in, \\\"Romantic\\\")') %&gt;%\n  filter(Romantic == TRUE) %&gt;%\n  mutate(genre = \"Romantic\") %&gt;%\n  select(-Romantic)\n\nnum_horror &lt;- horror_subgenre %&gt;%\n  filter(listed_in == \" \") %&gt;%\n  mutate(listed_in = \"none\") %&gt;%\n  rename(genre = listed_in) %&gt;%\n  select(genre, num)\n\nhorror_df &lt;- rbind(num_thrillers, num_comedies, num_action_adventure, num_scifi_fantasy, num_cult, num_documentaries, num_romantic, num_horror ) %&gt;%\n  as.data.frame() %&gt;%\n  arrange(desc(num)) %&gt;%\n  select(genre, num)\nhorror_df\n\n          genre num\n1          none 125\n2     Thrillers 110\n3      Comedies  38\n4 SciFi&Fantasy  19\n5          Cult  12\n6 Documentaties   2\n7      Romantic   2\n\n\n\nggplot(horror_df, aes(x = genre, y = num)) +\n  geom_bar(stat = \"identity\", aes(fill = genre)) + labs(\n    title = \"Subgenres among netflix horror movies\",\n    x = \"Subgenre of horror movie\",\n    y = \"Count\"\n  ) + \n  scale_x_discrete(guide = guide_axis(n.dodge=3)) +\n  guides(fill=guide_legend(title=\"Subgenres\"))\n\n\n\n\n\n\n\n\nBased on this plot of the number of horror movies with specific secondary genres, it seems most netflix horror movies either do not have a secondary genre or have thriller as their secondary genre. Other secondary genres appear less present among Netflix horror movies."
  },
  {
    "objectID": "Netflix_Analysis.html#netflix-tv-shows",
    "href": "Netflix_Analysis.html#netflix-tv-shows",
    "title": "Netflix Analysis",
    "section": "Netflix TV Shows",
    "text": "Netflix TV Shows\n\ndata &lt;- netflix %&gt;% \n  filter(type == \"TV Show\") %&gt;%\n  mutate(num_seasons = as.numeric(str_extract(duration, \"\\\\d+\" )))\n\nggplot(data, aes(x = release_year, y = num_seasons)) +\n  geom_point() +\n  xlim(1970,2025)+\n  geom_smooth(se = FALSE) + \n  labs(\n    title = \"Relationship between release year and number of seasons of netflix tv show\",\n    x = \"Release year\",\n    y = \"Number of seasons\"\n  )\n\n\n\n\n\n\n\n\nBased on this plot, the number of seasons that a Netflix show has tends to be lower for shows released between 2005 and 2020 than for other shows. Due to the discreteness of values on the x-axis, multiple points are most likely overlapping. This explains why it appears the right side of the graph has less points below the line of best fit than above it even with the line trending downwards.\nData source: https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv"
  },
  {
    "objectID": "Presentation.html#netflix-horror-movies",
    "href": "Presentation.html#netflix-horror-movies",
    "title": "Horror Movies and Simulation",
    "section": "Netflix Horror Movies",
    "text": "Netflix Horror Movies\n\nhorror_df\n\n  num         genre\n1 125        Horror\n2 110     Thrillers\n3  38      Comedies\n4  19 SciFi&Fantasy\n5  12          Cult\n6   2 Documentaties\n7   2      Romantic"
  },
  {
    "objectID": "Presentation.html#diversity-of-horror",
    "href": "Presentation.html#diversity-of-horror",
    "title": "Horror Movies and Simulation",
    "section": "Diversity of Horror",
    "text": "Diversity of Horror"
  },
  {
    "objectID": "Presentation.html#netflix-horror-movies-1",
    "href": "Presentation.html#netflix-horror-movies-1",
    "title": "Horror Movies and Simulation",
    "section": "Netflix Horror Movies",
    "text": "Netflix Horror Movies"
  },
  {
    "objectID": "Presentation.html#beta-vs-normal-distribution",
    "href": "Presentation.html#beta-vs-normal-distribution",
    "title": "Horror Movies and Simulation",
    "section": "Beta vs Normal Distribution",
    "text": "Beta vs Normal Distribution"
  },
  {
    "objectID": "Presentation.html#simulations",
    "href": "Presentation.html#simulations",
    "title": "Horror Movies and Simulation",
    "section": "Simulations",
    "text": "Simulations\n\n\n     n PI_percentage     lower     upper     cover alpha beta mean_in_interval\n1  455          0.95 0.4518613 0.5493738 0.9449629   193  193             TRUE\n2  370          0.95 0.4073973 0.5872232 0.9461831    57   57             TRUE\n3   32          0.95 0.2988644 0.6482433 0.9203282    13   13             TRUE\n4  452          0.95 0.4412301 0.5585745 0.9327327   121  121             TRUE\n5  474          0.95 0.4474210 0.5559983 0.9541341   169  169             TRUE\n6  381          0.95 0.4275185 0.5746540 0.9428899    83   83             TRUE\n7  265          0.95 0.4457077 0.5515220 0.9484484   169  169             TRUE\n8   92          0.95 0.4444017 0.5499518 0.9579876   187  187             TRUE\n9   55          0.95 0.4454341 0.5509372 0.9636713   197  197             TRUE\n10  56          0.95 0.4414381 0.5691853 0.9253503    99   99             TRUE"
  },
  {
    "objectID": "Presentation.html#results",
    "href": "Presentation.html#results",
    "title": "Horror Movies and Simulation",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "Presentation.html#function-1-pi-interval-calculation",
    "href": "Presentation.html#function-1-pi-interval-calculation",
    "title": "Horror Movies and Simulation",
    "section": "Function 1: PI Interval Calculation",
    "text": "Function 1: PI Interval Calculation\n\nCI &lt;- function(data, coverage_prob){ \n  #Generates a normal prediction interval with an intended coverage probability of coverage_prob based on a vector of numeric data\n  lower_zscore &lt;- qnorm((1-coverage_prob)/2)\n  upper_zscore &lt;- qnorm(((1-coverage_prob)/2) + coverage_prob)\n  avg &lt;- mean(data)\n  stan_d &lt;- sd(data)\n  lower_bound &lt;- avg + lower_zscore*stan_d\n  upper_bound &lt;- avg + upper_zscore*stan_d\n  return(data.frame(PI_percentage = coverage_prob, lower = lower_bound, upper = upper_bound))\n}"
  },
  {
    "objectID": "Presentation.html#function-2-one-simulation-of-beta-generated-data",
    "href": "Presentation.html#function-2-one-simulation-of-beta-generated-data",
    "title": "Horror Movies and Simulation",
    "section": "Function 2: One simulation of beta-generated data",
    "text": "Function 2: One simulation of beta-generated data\n\none_beta_simulation &lt;- function(n, alpha, beta, ci_prop){\n  #Assesses prediction accuracy and actual coverage probability of a normal prediction interval when used on a vector of numeric data of size n. The numeric data is generated from a beta distribution with parameters alpha and beta.\n  \n  cover_df &lt;- CI(rbeta(n, alpha, beta), ci_prop)\n  cover_prop &lt;- pbeta(cover_df[1, \"upper\"], alpha, beta) - pbeta(cover_df[1, \"lower\"], alpha, beta)\n  mean_in_interval &lt;- .5 &gt;= cover_df[1, \"lower\"] & .5 &lt;= cover_df[1,\"upper\"]\n  param_df &lt;- data.frame(cover = cover_prop, alpha = rep(alpha, nrow(cover_df)), beta = rep(beta, nrow(cover_df)), mean_in_interval = mean_in_interval)\n  df &lt;- cbind(cover_df, param_df)\n  return(df)\n}"
  },
  {
    "objectID": "Presentation.html#function-3-multiple-beta-simulations",
    "href": "Presentation.html#function-3-multiple-beta-simulations",
    "title": "Horror Movies and Simulation",
    "section": "Function 3: Multiple Beta simulations",
    "text": "Function 3: Multiple Beta simulations\n\nbeta_sims_n &lt;- function(n){\n  #Iterates over a vector of possible alpha = beta values and applies one_beta_simulation to each possible value of alpha/beta. All simulations use data of sample size n.\n  df1 &lt;- map(parameters,\\(param) one_beta_simulation(n, param, param, ci) ) %&gt;%\n  list_rbind()\n  df2 &lt;- data.frame(n = rep(n, nrow(df1)))\n  df &lt;- cbind(df2, df1)\n  return(df)\n}"
  }
]