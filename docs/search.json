[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "shirleytor.github.io",
    "section": "",
    "text": "Hello there! Welcome to my website!\nI’m Shirley Toribio, a statistics student at Pomona College. My interests include machine learning, biostatistics, and topological data analysis. Feel free to look around my website!\n\n\n\nArt by me\n\n\nThis is a link to the github repository hosting this website: https://github.com/shirleytor/shirleytor.github.io"
  },
  {
    "objectID": "data_viz.html",
    "href": "data_viz.html",
    "title": "Data Visualization",
    "section": "",
    "text": "This analysis looks at world fairs. According to Wikipedia,\n\na world’s fair, also known as a universal exhibition or an expo, is a large global exhibition designed to showcase the achievements of nations. These exhibitions vary in character and are held in different parts of the world at a specific site for a period of time, typically between three and six months.\n\nDue to various factors, however, it is possible that world fairs might not be as representative of nations worldwide as their description and name would suggest. Ideally, as many nations as possible should be included in a world fair in order for it to be truly representative. As such, I track the number of countries that have attended world fairs from 1851 to 2021 to see how world fairs have evolved in terms of country representation.\n\n\n\n\n\n\n\n\n\nBased on the upward trend of the line of best fit, world fairs seem to have become more inclusive of countries as time has gone by. This trend towards increased inclusivity of countries seems to be especially present from 1975 to 2021. Modern world fair thus seem more representative of countries worldwide than world fairs of the past.\nData source here."
  },
  {
    "objectID": "data_viz.html#analyzing-data-on-world-fairs-from-1855-to-2022",
    "href": "data_viz.html#analyzing-data-on-world-fairs-from-1855-to-2022",
    "title": "Data Visualization",
    "section": "",
    "text": "This analysis looks at world fairs. According to Wikipedia,\n\na world’s fair, also known as a universal exhibition or an expo, is a large global exhibition designed to showcase the achievements of nations. These exhibitions vary in character and are held in different parts of the world at a specific site for a period of time, typically between three and six months.\n\nDue to various factors, however, it is possible that world fairs might not be as representative of nations worldwide as their description and name would suggest. Ideally, as many nations as possible should be included in a world fair in order for it to be truly representative. As such, I track the number of countries that have attended world fairs from 1851 to 2021 to see how world fairs have evolved in terms of country representation.\n\n\n\n\n\n\n\n\n\nBased on the upward trend of the line of best fit, world fairs seem to have become more inclusive of countries as time has gone by. This trend towards increased inclusivity of countries seems to be especially present from 1975 to 2021. Modern world fair thus seem more representative of countries worldwide than world fairs of the past.\nData source here."
  },
  {
    "objectID": "data_viz.html#total-carbon-dioxide-emissions-from-major-natural-resource-companies",
    "href": "data_viz.html#total-carbon-dioxide-emissions-from-major-natural-resource-companies",
    "title": "Data Visualization",
    "section": "Total carbon dioxide emissions from major natural resource companies",
    "text": "Total carbon dioxide emissions from major natural resource companies\nThis analysis looks at emissions of carbon dioxide from major natural resource companies. The dataset used for this analysis originates from a Carbon Majors database.\n\n\n\n\n\n\n\n\n\nBased on this graph, the production of oil, natural gas, and coal seems to be mostly responsible for the amount of carbon dioxide emitted by major natural resource companies. Major natural resource companies should thus look into reducing their production of these commodities and shifting towards production of other commodoties in order to reduce their carbon dioxide emissions.\nData source here."
  },
  {
    "objectID": "project3_ds.html",
    "href": "project3_ds.html",
    "title": "Simulation Study",
    "section": "",
    "text": "Symmetric beta distributions and normal distributions are very similar to each other in shape. Due to this, in this project I examine how a 95% prediction interval that assumes data originates from a normal distribution would fare in terms of prediction accuracy and actual coverage probability of beta-distributed data. I define a confidence interval with “good” prediction accuracy as one that covers the actual mean of the data’s parent distribution, and a confidence interval with good coverage probability as one that covers approximately .95 of the beta distribution. All data is generated from beta distributions with mean .5."
  },
  {
    "objectID": "project3_ds.html#introduction",
    "href": "project3_ds.html#introduction",
    "title": "Simulation Study",
    "section": "",
    "text": "Symmetric beta distributions and normal distributions are very similar to each other in shape. Due to this, in this project I examine how a 95% prediction interval that assumes data originates from a normal distribution would fare in terms of prediction accuracy and actual coverage probability of beta-distributed data. I define a confidence interval with “good” prediction accuracy as one that covers the actual mean of the data’s parent distribution, and a confidence interval with good coverage probability as one that covers approximately .95 of the beta distribution. All data is generated from beta distributions with mean .5."
  },
  {
    "objectID": "project3_ds.html#simulations",
    "href": "project3_ds.html#simulations",
    "title": "Simulation Study",
    "section": "Simulations",
    "text": "Simulations\nFirst, I tidy up.\n\nlibrary(tidyverse)\n\nThen, I define a few functions that will help me in my task.\n\nCI &lt;- function(data, coverage_prob){ \n  #Generates a normal prediction interval with an intended coverage probability of coverage_prob based on a vector of numeric data\n  \n  lower_zscore &lt;- qnorm((1-coverage_prob)/2)\n  upper_zscore &lt;- qnorm(((1-coverage_prob)/2) + coverage_prob)\n  avg &lt;- mean(data)\n  stan_d &lt;- sd(data)\n  lower_bound &lt;- avg + lower_zscore*stan_d\n  upper_bound &lt;- avg + upper_zscore*stan_d\n  return(data.frame(PI_percentage = coverage_prob, lower = lower_bound, upper = upper_bound))\n}\n\none_beta_simulation &lt;- function(n, alpha, beta, ci_prop){\n  #Assesses prediction accuracy and actual coverage probability of a normal prediction interval when used on a vector of numeric data of size n. The numeric data is generated from a beta distribution with parameters alpha and beta.\n  \n  cover_df &lt;- CI(rbeta(n, alpha, beta), ci_prop)\n  cover_prop &lt;- pbeta(cover_df[1, \"upper\"], alpha, beta) - pbeta(cover_df[1, \"lower\"], alpha, beta)\n  mean_in_interval &lt;- .5 &gt;= cover_df[1, \"lower\"] & .5 &lt;= cover_df[1,\"upper\"]\n  param_df &lt;- data.frame(cover = cover_prop, alpha = rep(alpha, nrow(cover_df)), beta = rep(beta, nrow(cover_df)), mean_in_interval = mean_in_interval)\n  df &lt;- cbind(cover_df, param_df)\n  return(df)\n}\n\nbeta_sims_n &lt;- function(n){\n  #Iterates over a vector of possible alpha = beta values and applies one_beta_simulation to each possible value of alpha/beta. All simulations use data of sample size n.\n  df1 &lt;- map(parameters,\\(param) one_beta_simulation(n, param, param, ci) ) %&gt;%\n  list_rbind()\n  df2 &lt;- data.frame(n = rep(n, nrow(df1)))\n  df &lt;- cbind(df2, df1)\n  return(df)\n}\n\nTime to simulate over different parameter values and sample sizes!\n\nparameters &lt;- seq(5, 200, by = 2)\nn &lt;- 2:500\nci &lt;- .95\n\nbeta_df &lt;- map(n, \\(n) beta_sims_n(n)) %&gt;%\n  list_rbind()\n\nThis is a glimpse at the results of the simulations.\n\nrows &lt;- sample(1:nrow(beta_df), 10)\nmap(rows, \\(i) beta_df[i,]) %&gt;%\n  list_rbind()\n\n     n PI_percentage     lower     upper     cover alpha beta mean_in_interval\n1  247          0.95 0.4523062 0.5547580 0.9355907   165  165             TRUE\n2   83          0.95 0.4359215 0.5669415 0.9650810   129  129             TRUE\n3  170          0.95 0.4418966 0.5511343 0.9487325   161  161             TRUE\n4  350          0.95 0.4462158 0.5532432 0.9619462   187  187             TRUE\n5  135          0.95 0.4451088 0.5587557 0.9621922   167  167             TRUE\n6  415          0.95 0.4475184 0.5524290 0.9621266   195  195             TRUE\n7  331          0.95 0.4430825 0.5614637 0.9531166   141  141             TRUE\n8  471          0.95 0.4038219 0.6013108 0.9345494    43   43             TRUE\n9  199          0.95 0.4199542 0.5844024 0.9165128    55   55             TRUE\n10 348          0.95 0.4325954 0.5677737 0.9326805    91   91             TRUE\n\n\nThis is a random sample of rows from the actual dataset, which has 48902 rows and 8 columns. Each row corresponds to a simulated random sample of size n from a beta distribution with parameters alpha and beta. For each random sample, a normal prediction interval was generated with bounds “lower” and “upper”. “PI_percentage” refers to the intended coverage probability and “cover” refers to the actual coverage probability of said prediction interval over the beta distribution the data was generated from. “mean_in_interval” is a binary variable that states if the prediction interval covered the mean of the distribution."
  },
  {
    "objectID": "project3_ds.html#insights",
    "href": "project3_ds.html#insights",
    "title": "Simulation Study",
    "section": "Insights",
    "text": "Insights\n\nn_means_df &lt;- beta_df %&gt;%\n  mutate(diff = cover - PI_percentage) %&gt;%\n  group_by(n) %&gt;%\n  summarize(mean = mean(diff), mu_in_interval = sum(mean_in_interval)/n()) %&gt;%\n  filter(n %in% 1:100)\n\nggplot(n_means_df, aes(x = n, y = mean)) + \n  geom_point() + \n  geom_hline(yintercept = 0, col = \"black\")  +\n  labs(\n    x = \"sample size\",\n    y = \"difference between actual and intended coverage\",\n    title = \"Figure 1\",\n    subtitle = \"difference between actual and intended coverage probability based on sample size\",\n  )\n\n\n\n\n\n\n\n\nFigure 1 graphs the mean difference between the actual coverage probability and intended coverage probability (calculated as: actual coverage probability - intended coverage probability) per each sample size from 2 to 100. A negative mean difference indicates the actual coverage probability tended to be less than the intended coverage probability, which is undesirable. For sample sizes from 2 to around 13, the mean differences tend to be much lower than 0, meaning the prediction interval is likely to cover less than intended. As the sample size increases, this mean difference seems to converge in probability to 0, meaning the actual coverage probability is more likely to match the intended coverage probability.\nFor small sample sizes it seems likely a normal prediction interval will cover less than intended, with it seeming to cover less the smaller the sample size is.\n\nn_means_df &lt;- beta_df %&gt;%\n  mutate(diff = cover - PI_percentage) %&gt;%\n  group_by(n) %&gt;%\n  summarize(mean = mean(diff), mu_in_interval = sum(mean_in_interval)/n()) %&gt;%\n  filter(n %in% 1:30)\n\nggplot(n_means_df, aes(x = n, y = mu_in_interval)) + \n  geom_point()  +\n  labs(\n    x = \"sample size\",\n    y = \"proportion of mu-inclusive prediction intervals\",\n    title = \"Figure 2\",\n    subtitle = \"proportion of mu-inclusive prediction intervals based on sample size\"\n  )\n\n\n\n\n\n\n\n\nFigure 2 plots the proportion of prediction intervals that cover mu = .5 per each sample size from 2 to 30. These points converge to 1 at a sample size of around 10, meaning for sample sizes of 10 or greater it is probable that all random samples with those samples sizes will produce normal-prediction intervals that cover the mean of the beta distribution said data originated from. Based on this plot, the normal-prediction interval fares well with accepting the null hypothesis of mu = .5 given the null distribution is symmetric and beta.\n\nns_of_interest &lt;- c(5, 10, 30, 50, 100, 500)\nbeta_df_2 &lt;- filter(beta_df,n %in% ns_of_interest) %&gt;%\n  mutate(sample_size = as.factor(n))\nggplot(beta_df_2, aes(x = alpha, y = cover, color = sample_size)) +\n  geom_point() +\n  geom_smooth(aes(line = n ), se = FALSE) +\n  labs(\n    x = \"value of alpha and beta\",\n    y = \"actual coverage probability\",\n    title = \"Figure 3\",\n    subtitle = \"actual coverage probability based on parameter values\"\n  )\n\n\n\n\n\n\n\n\nFigure 3 plots the actual coverage probability per each value of alpha and beta. Points and lines are colored based on sample size, which are described in the legend. Alpha and beta have the same values, by the way. All the lines of best fit seem close to being horizontal, meaning that there most likely is not a relationship between the values of alpha/beta and the actual coverage probability of the data. Based on the y-intercepts of each line and the vertical spread of points given sample size, normal prediction intervals based on small amounts of data seem more likely to deviate from the intended coverage probability of the data’s parent symmetric beta distribution and to deviate to being lower than .95."
  },
  {
    "objectID": "project3_ds.html#conclusion",
    "href": "project3_ds.html#conclusion",
    "title": "Simulation Study",
    "section": "Conclusion",
    "text": "Conclusion\nBy generating data from symmetric beta distributions with mu = .5 and making normal prediction intervals based on this data, I was able to assess the predictive accuracy and actual coverage probability of normal prediction intervals when applied to symmetric-beta data. Even for sample sizes as small as 10, normal prediction intervals seem to have good predictive accuracy, although their coverage probability is quite poor for sample sizes below 30. When the null hypothesis is mu = .5, it appears they are quite adept at avoiding type I errors."
  },
  {
    "objectID": "proj4.html",
    "href": "proj4.html",
    "title": "SQL",
    "section": "",
    "text": "I plan to query data from the Wideband Acoustic Immittance Database, which is a repository of auditory measurements from different people. From this data, two graphs will be generated. One graph will replicate Figure 1 from Voss(2020) and the other will compare mean absorbance measurements between people of different sexes over different frequencies.\n\nlibrary(RMariaDB)\nlibrary(dbplyr)\nlibrary(dplyr)\nlibrary(tidyverse)\n\n\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n #collect(Measurements)\n\nYou can add options to executable code like this\n\nSELECT Measurements.Identifier,\n       Measurements.Frequency,\n       AVG(Absorbance) AS mean_absorbance,\n       PI_Info.AuthorsShortList AS authors\nFROM Measurements\nJOIN PI_Info ON Measurements.Identifier = PI_Info.Identifier\nGROUP BY Measurements.Identifier, Measurements.Frequency;\n\n\ntable1 %&gt;%\n  filter(authors %in% c(\"Abur et al.\", \"Feeney et al.\", \"Groon et al.\", \"Lewis and Neely\", \"Liu et al.\", \"Rosowski et al.\", \"Shahnaz et al.\", \"Shaver and Sun\", \"Sun et al.\", \"Voss and Allen\", \"Voss et al.\", \"Werner et al.\")) %&gt;%\n  ggplot(aes(x = Frequency, y = mean_absorbance)) +\n  geom_smooth(aes(color = authors), se = FALSE) +\n  xlim(0, 8000)\n\n\n\n\n\n\n\n\nThe echo: false option disables the printing of code (only output is displayed).\n\nSELECT\n  Subjects.Sex AS sex,\n  Subjects.Race AS race,\n  Subjects.Ethnicity AS ethnicity,\n  Subjects.Identifier,\n  Measurements.Identifier,\n  Measurements.Frequency AS freq,\n  AVG(Measurements.Absorbance) AS mean_absorbance\nFROM Subjects\nJOIN Measurements ON Subjects.SubjectNumber = Measurements.SubjectNumber \nWHERE Subjects.Identifier = \"Aithal_2013\" AND Measurements.Identifier = \"Aithal_2013\"\nGROUP BY ethnicity, race, sex, freq;\n\n\ntable2 &lt;- table2[,-c(4)]\ntable2 %&gt;%\n  ggplot(aes(x = freq, y = mean_absorbance, color = sex)) +\n  geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\nUsing SQL queries, I filtered through and sorted data in a manner that allowed me to compare absorbance measurements across sexes and copy figure 1 of Voss(2020). I did this with 2 SQL queries and joined different tables from the same database to produce both graphs. Following each query, I used ggplot to plot mean absorbance measurements alongside frequency."
  },
  {
    "objectID": "SQL_Proj.html",
    "href": "SQL_Proj.html",
    "title": "Wideband Acoustic Immittance Data Visualization",
    "section": "",
    "text": "I plan to query data from the Wideband Acoustic Immittance Database, which is a repository of auditory measurements from different people. From this data, two graphs will be generated. One graph will replicate Figure 1 from Voss(2019) and the other will compare mean absorbance measurements between babies of different sexes over different frequencies using data from Aithal et al.(2013).\nThis is the abstract of Aithal et al.(2013):\n\nPresently, normative wideband reflectance data are available for neonates who have passed a distortion product otoacoustic emission test. However, passing the distortion product otoacoustic emission test alone does not ensure normal middle ear function. The objective of this study was to establish normative wideband reflectance data in healthy neonates with normal middle ear function, as justified by passing a battery of tests.\n\nVoss(2019) is a summarization of different studies analyzing auditory measurements among people.\n\nlibrary(RMariaDB)\nlibrary(dbplyr)\nlibrary(dplyr)\nlibrary(tidyverse)\n\n\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n #collect(Measurements)\n\n\nSELECT Measurements.Identifier,\n       Measurements.Frequency,\n       AVG(Absorbance) AS mean_absorbance,\n       CONCAT(PI_Info.AuthorsShortList,\" (\", PI_Info.Year, \")\",\" N=\", COUNT(DISTINCT Measurements.SubjectNumber) ,\"; \",Measurements.Instrument) AS studies\nFROM Measurements\nJOIN PI_Info ON Measurements.Identifier = PI_Info.Identifier\nWHERE PI_Info.AuthorsShortList IN (\"Abur et al.\", \"Feeney et al.\", \"Groon et al.\", \"Lewis and Neely\", \"Liu et al.\", \"Rosowski et al.\", \"Shahnaz et al.\", \"Shaver and Sun\", \"Sun et al.\", \"Voss and Allen\", \"Voss et al.\", \"Werner et al.\") AND Measurements.Frequency BETWEEN 0 and 8000\nGROUP BY Measurements.Identifier, Measurements.Frequency,  Measurements.Instrument;\n\n\ntable1 %&gt;%\n  ggplot(aes(x = Frequency, y = mean_absorbance)) +\n  geom_line(aes(color = studies), se = FALSE) + \n  labs(\n    title = \"Mean absorbance from publications in WAI database\"\n  )\n\n\n\n\n\n\n\n\n\nSELECT\n  Subjects.Sex AS sex,\n  Subjects.Race AS race,\n  Subjects.Ethnicity AS ethnicity,\n  Subjects.Identifier,\n  Measurements.Frequency AS freq,\n  AVG(Measurements.Absorbance) AS mean_absorbance\nFROM Subjects\nJOIN Measurements ON Subjects.SubjectNumber = Measurements.SubjectNumber \nWHERE Subjects.Identifier = \"Aithal_2013\" AND Measurements.Identifier = \"Aithal_2013\"\nGROUP BY ethnicity, race, sex, freq;\n\n\ntable2 %&gt;%\n  ggplot(aes(x = freq, y = mean_absorbance, color = sex)) +\n  geom_line(se = FALSE) +\n  labs(\n    title = \"Mean absorbance from babies of different sexes\"\n  )\n\n\n\n\n\n\n\n\nUsing SQL queries, I filtered through and sorted data in a manner that allowed me to compare absorbance measurements across babies of different sexes with data from Aithal(2013)and copy figure 1 of Voss(2019). I did this with 2 SQL queries and joined different tables from the same database to produce both graphs. Following each query, I used ggplot to plot mean absorbance measurements alongside frequency.\n\n\nAithal et al. 2013. “Normative wideband reflectance measures in healthy neonates.” International Journal of Pediatric Otorhinolaryngology 77 (1). https://doi.org/10.1016/j.ijporl.2012.09.02\nVoss, SE. 2019. “Resource Review.” Ear and Hearing 40 (6). https://doi.org/10.1097/AUD.0000000000000790."
  },
  {
    "objectID": "Project 2/Netflix_Analysis.html",
    "href": "Project 2/Netflix_Analysis.html",
    "title": "Analysis of Netflix Horror Movies and TV Shows",
    "section": "",
    "text": "library(RTextTools) \nlibrary(tidyverse)\nlibrary(tidytuesdayR)\nnetflix &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv')"
  },
  {
    "objectID": "Project 2/Netflix_Analysis.html#netflix-horror-movies",
    "href": "Project 2/Netflix_Analysis.html#netflix-horror-movies",
    "title": "Analysis of Netflix Horror Movies and TV Shows",
    "section": "Netflix Horror Movies",
    "text": "Netflix Horror Movies\n\nhorror_subgenre &lt;- netflix %&gt;%\n  filter(str_detect(listed_in, \"Horror\"), type == \"Movie\") %&gt;%\n  mutate(listed_in = str_remove(listed_in, \", International Movies\")) %&gt;%\n  mutate(listed_in = str_remove(listed_in, \", Independent Movies\")) %&gt;%\n  mutate(listed_in = str_remove_all(listed_in, \"[,]\")) %&gt;%\n  mutate(listed_in = str_remove_all(listed_in, \"Movies\")) %&gt;%\n  mutate(listed_in = str_replace(listed_in, \"[:space:]&[:space:]\", \"&\")) %&gt;%\n  group_by(listed_in) %&gt;%\n  summarize(num = n()) %&gt;%\n  arrange(desc(num)) %&gt;%\n  mutate(listed_in = str_remove(listed_in, \"Horror\"))\n\n\nnum_thrillers &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Thrillers\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Thrillers = 'str_detect(listed_in, \\\"Thrillers\\\")') %&gt;%\n  filter(Thrillers == TRUE) %&gt;%\n  mutate(genre = \"Thrillers\") %&gt;%\n  select(-Thrillers)\n\nnum_comedies &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Comedies\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Comedies = 'str_detect(listed_in, \\\"Comedies\\\")') %&gt;%\n  filter(Comedies == TRUE) %&gt;%\n  mutate(genre = \"Comedies\") %&gt;%\n  select(-Comedies)\n\n\nnum_action_adventure &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Action/Adventure\"))%&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Action_Adventure = 'str_detect(listed_in, \\\"Action/Adventure\\\")') %&gt;%\n  filter(Action_Adventure == TRUE) %&gt;%\n  mutate(genre = \"Action&Adventure\") %&gt;%\n  select(-Action_Adventure)\n\nnum_scifi_fantasy &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Sci-Fi&Fantasy\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(SciFi_Fantasy = 'str_detect(listed_in, \\\"Sci-Fi&Fantasy\\\")') %&gt;%\n  filter(SciFi_Fantasy == TRUE) %&gt;%\n  mutate(genre = \"SciFi&Fantasy\") %&gt;%\n  select(-SciFi_Fantasy)\n\nnum_cult &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Cult\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Cult = 'str_detect(listed_in, \\\"Cult\\\")') %&gt;%\n  filter(Cult == TRUE) %&gt;%\n  mutate(genre = \"Cult\") %&gt;%\n  select(-Cult)\n\nnum_documentaries &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Documentaries\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Documentaries = 'str_detect(listed_in, \\\"Documentaries\\\")') %&gt;%\n  filter(Documentaries == TRUE)%&gt;%\n  mutate(genre = \"Documentaties\") %&gt;%\n  select(-Documentaries)\n\nnum_romantic &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Romantic\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Romantic = 'str_detect(listed_in, \\\"Romantic\\\")') %&gt;%\n  filter(Romantic == TRUE) %&gt;%\n  mutate(genre = \"Romantic\") %&gt;%\n  select(-Romantic)\n\nnum_horror &lt;- horror_subgenre %&gt;%\n  filter(listed_in == \" \") %&gt;%\n  mutate(listed_in = \"horror\") %&gt;%\n  rename(genre = listed_in)\n\nhorror_df &lt;- rbind(num_thrillers, num_comedies, num_action_adventure, num_scifi_fantasy, num_cult, num_documentaries, num_romantic, num_horror ) %&gt;%\n  as.data.frame() %&gt;%\n  arrange(desc(num))\nhorror_df\n\n  num         genre\n1 125        horror\n2 110     Thrillers\n3  38      Comedies\n4  19 SciFi&Fantasy\n5  12          Cult\n6   2 Documentaties\n7   2      Romantic\n\n\n\nggplot(horror_df, aes(x = genre, y = num)) +\n  geom_bar(stat = \"identity\", aes(fill = genre)) + labs(\n    title = \"Subgenres among netflix horror movies\",\n    x = \"Subgenre of horror movie\",\n    y = \"Count\"\n  ) + \n  scale_x_discrete(guide = guide_axis(n.dodge=3)) +\n  guides(fill=guide_legend(title=\"Subgenres\"))\n\n\n\n\n\n\n\n\nBased on this plot of the number of horror movies with specific subgenres, it seems most netflix horror movies either do not have a subgenre or have thriller as their subgenre. Other subgenres appear substantially less present among Netflix horror movies."
  },
  {
    "objectID": "Project 2/Netflix_Analysis.html#netflix-tv-shows",
    "href": "Project 2/Netflix_Analysis.html#netflix-tv-shows",
    "title": "Analysis of Netflix Horror Movies and TV Shows",
    "section": "Netflix TV Shows",
    "text": "Netflix TV Shows\n\ndata &lt;- netflix %&gt;% \n  filter(type == \"TV Show\") %&gt;%\n  mutate(num_seasons = as.numeric(str_extract(duration, \"\\\\d+\" )))\n\nggplot(data, aes(x = release_year, y = num_seasons)) +\n  geom_point() +\n  xlim(1970,2025)+\n  geom_smooth(se = FALSE) + \n  labs(\n    title = \"Relationship between release year and number of seasons of netflix tv show\",\n    x = \"Release year\",\n    y = \"Number of seasons\"\n  )\n\n\n\n\n\n\n\n\nBased on this plot, the number of seasons that a Netflix show has tends to be lower for shows released between 2005 and 2020 than for other shows. Due to the discreteness of values on the x-axis, multiple points are most likely overlapping. This explains why it appears the right side of the graph has less points below the line of best fit than above it even with the line trending downwards.\nData source: https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv"
  },
  {
    "objectID": "Beta_Simulation.html",
    "href": "Beta_Simulation.html",
    "title": "Simulation",
    "section": "",
    "text": "Symmetric beta distributions and normal distributions are very similar to each other in shape. Due to this, in this project I examine how a 95% prediction interval that assumes data originates from a normal distribution would fare in terms of prediction accuracy and actual coverage probability of beta-distributed data. I define a prediction interval with “good” prediction accuracy as one that covers the actual mean of the data’s parent distribution, and a prediction interval with good coverage probability as one that covers approximately .95 of the beta distribution. All data is generated from beta distributions with mean .5."
  },
  {
    "objectID": "Beta_Simulation.html#introduction",
    "href": "Beta_Simulation.html#introduction",
    "title": "Simulation",
    "section": "",
    "text": "Symmetric beta distributions and normal distributions are very similar to each other in shape. Due to this, in this project I examine how a 95% prediction interval that assumes data originates from a normal distribution would fare in terms of prediction accuracy and actual coverage probability of beta-distributed data. I define a prediction interval with “good” prediction accuracy as one that covers the actual mean of the data’s parent distribution, and a prediction interval with good coverage probability as one that covers approximately .95 of the beta distribution. All data is generated from beta distributions with mean .5."
  },
  {
    "objectID": "Beta_Simulation.html#simulations",
    "href": "Beta_Simulation.html#simulations",
    "title": "Simulation",
    "section": "Simulations",
    "text": "Simulations\nFirst, I tidy up.\n\nlibrary(tidyverse)\n\nThen, I define a few functions that will help me in my task.\n\nPI &lt;- function(data, coverage_prob){ \n  #Generates a normal prediction interval with an intended coverage probability of coverage_prob based on a vector of numeric data\n  n &lt;- length(data)\n  lower_tscore &lt;- qt((1-coverage_prob)/2, df = n - 1)\n  upper_tscore &lt;- qt(((1-coverage_prob)/2) + coverage_prob, df = n - 1)\n  avg &lt;- mean(data)\n  stan_d &lt;- sd(data)\n  lower_bound &lt;- avg + lower_tscore*stan_d * sqrt(1 + (1/n))\n  upper_bound &lt;- avg + upper_tscore*stan_d * sqrt(1 + (1/n))\n  return(data.frame(PI_percentage = coverage_prob, lower = lower_bound, upper = upper_bound))\n}\n\nPI is a function that takes a vector of numeric data and produces a high-density prediction interval intended to cover the proportion of said data’s parent distribution given by coverage_prob. This prediction interval is created under the assumption that the data is normally distributed (although we know it is not). Let \\(s\\) be the sample standard deviation of our data, \\(n\\) be the size of our sample, \\(\\hat{p}\\) be the mean of our data, and \\(t_{p,n-1}\\) be the quantile value associated with the highest density coverage probability \\(p\\) in a \\(t\\) distribution with \\(n-1\\) degrees of freedom. If we assume that our data is normal, then the highest density prediction interval with coverage probability \\(p\\) is best predicted as\n\\[\\hat{p} \\pm t_{p,n-1}*s*\\sqrt{1+\\frac{1}{n}}\\] PI uses this formula to generate the bounds of its prediction interval.\n\none_beta_simulation &lt;- function(n, alpha, beta, pi_prop){\n  #Assesses prediction accuracy and actual coverage probability of a normal prediction interval when used on a vector of numeric data of size n. The numeric data is generated from a beta distribution with parameters alpha and beta.\n  \n  cover_df &lt;- PI(rbeta(n, alpha, beta), pi_prop)\n  \n  cover_prop &lt;- pbeta(cover_df[1, \"upper\"], alpha, beta) - pbeta(cover_df[1, \"lower\"], alpha, beta) #this is the proportion of the data's parent distribution that is actually covered by the normal prediction interval generated for said data.\n  \n  mean_in_interval &lt;- .5 &gt;= cover_df[1, \"lower\"] & .5 &lt;= cover_df[1,\"upper\"]\n  param_df &lt;- data.frame(cover = cover_prop, alpha = rep(alpha, nrow(cover_df)), beta = rep(beta, nrow(cover_df)), mean_in_interval = mean_in_interval)\n  df &lt;- cbind(cover_df, param_df)\n  return(df)\n}\n\none_beta_simulation randomly samples \\(n\\) data points from a beta distribution with parameters alpha and beta and calculates a normal prediction interval for said data using function PI. It then determines what proportion of the data’s parent beta distribution is covered by the prediction interval and checks if the mean of said distribution is covered by the prediction interval.\n\nbeta_sims_n &lt;- function(n){\n  #Iterates over a vector of possible alpha = beta values and applies one_beta_simulation to each possible value of alpha/beta. All simulations use data of sample size n.\n  df1 &lt;- map(parameters,\\(param) one_beta_simulation(n, param, param, pi) ) %&gt;%\n  list_rbind()\n  df2 &lt;- data.frame(n = rep(n, nrow(df1)))\n  df &lt;- cbind(df2, df1)\n  return(df)\n}\n\nbeta_sims_n maps over a vector of potential parameter values for a beta distribution with mean \\(.5\\) and uses one_beta_simulation per each iteration, with all iterations taking the same value for the data’s sample size. It randomly samples \\(n\\) points multiple times from different beta distribution with mean .5 and generates normal prediction intervals for each sample. It also determines the proportion of the each sample’s parent distribution that said intervals actually cover.\nTime to simulate over different parameter values and sample sizes!\n\nparameters &lt;- seq(5, 200, by = 2)\nn &lt;- 2:500\npi &lt;- .95\n\nbeta_df &lt;- map(n, \\(n) beta_sims_n(n)) %&gt;%\n  list_rbind()\n\nThis is a glimpse at the results of the simulations.\n\nrows &lt;- sample(1:nrow(beta_df), 10)\nmap(rows, \\(i) beta_df[i,]) %&gt;%\n  list_rbind()\n\n     n PI_percentage     lower     upper     cover alpha beta mean_in_interval\n1  119          0.95 0.4425942 0.5594488 0.9399698   129  129             TRUE\n2  420          0.95 0.4182923 0.5771250 0.9599025    83   83             TRUE\n3   89          0.95 0.4329045 0.5736984 0.9585099   105  105             TRUE\n4  110          0.95 0.4493292 0.5458561 0.9439310   197  197             TRUE\n5  392          0.95 0.3452496 0.6563130 0.9492547    19   19             TRUE\n6  494          0.95 0.4417945 0.5579416 0.9609310   157  157             TRUE\n7  460          0.95 0.2223840 0.7903329 0.9456662     5    5             TRUE\n8  365          0.95 0.4251919 0.5773645 0.9419651    77   77             TRUE\n9  352          0.95 0.4417557 0.5629539 0.9535169   135  135             TRUE\n10  13          0.95 0.4057513 0.6377786 0.9750873    55   55             TRUE\n\n\nThis is a random sample of rows from the actual dataset, which has 48902 rows and 8 columns. Each row corresponds to a simulated random sample of size n from a beta distribution with parameters alpha and beta. For each random sample, a normal prediction interval was generated with bounds “lower” and “upper”. “PI_percentage” refers to the intended coverage probability and “cover” refers to the actual coverage probability of said prediction interval over the beta distribution the data was generated from. “mean_in_interval” is a binary variable that states if the prediction interval covered the mean of the distribution."
  },
  {
    "objectID": "Beta_Simulation.html#insights",
    "href": "Beta_Simulation.html#insights",
    "title": "Simulation",
    "section": "Insights",
    "text": "Insights\n\nn_means_df &lt;- beta_df %&gt;%\n  mutate(diff = cover - PI_percentage) %&gt;%\n  group_by(n) %&gt;%\n  summarize(mean = mean(diff), mu_in_interval = sum(mean_in_interval)/n())\navg &lt;- mean(n_means_df$mean)\n\n\nggplot(n_means_df, aes(x = n, y = mean)) + \n  geom_point() + \n  geom_hline(yintercept = 0, col = \"black\")  +\n  geom_hline(yintercept = avg, col = \"red\")  +\n  labs(\n    x = \"sample size\",\n    y = \"mean difference between actual and intended coverage\",\n    title = \"Figure 1\",\n    subtitle = \"difference between actual and intended coverage probability based on sample size\",\n  )\n\n\n\n\n\n\n\n\nFigure 1 graphs the mean difference between the actual coverage probability and intended coverage probability (calculated as: actual coverage probability - intended coverage probability) per each sample size from 2 to 500. A negative mean difference indicates the actual coverage probability tended to be less than the intended coverage probability, which is undesirable, while a positive mean difference indicates the actual cover probability tended to be more than the intended coverage probability. The mean difference between actual and intended coverage probability seems to converge to a value a little bit above 0 as the sample size increases, indicating that actual coverage probability tends to be more than the intended coverage and that this is more so as sample size increases.\nFor small sample sizes the mean difference between actual and intended coverage probability has a lot more variance around 0 than it does for larger sample sizes, which can be attributed to sampling variability. Overall, absolute differences in actual coverage probability and intended coverage probability don’t appear to extend beyond .02, indicating normal prediction intervals tend to have good coverage probability for symmetric, beta distributed data.\n\nn_means_df &lt;- beta_df %&gt;%\n  mutate(diff = cover - PI_percentage) %&gt;%\n  group_by(n) %&gt;%\n  summarize(mean = mean(diff), mu_in_interval = sum(mean_in_interval)/n()) %&gt;%\n  filter(n %in% 1:30)\n\n\nggplot(n_means_df, aes(x = n, y = mu_in_interval)) + \n  geom_point()  +\n  labs(\n    x = \"sample size\",\n    y = \"proportion of mu-inclusive prediction intervals\",\n    title = \"Figure 2\",\n    subtitle = \"proportion of mu-inclusive prediction intervals based on sample size\"\n  )\n\n\n\n\n\n\n\n\nFigure 2 plots the proportion of prediction intervals that cover mu = .5 per each sample size from 2 to 30. These points converge to 1 at a sample size of around 4, meaning for sample sizes of 4 or greater it is probable that all random samples with those samples sizes will produce normal-prediction intervals that cover the mean of the beta distribution said data originated from.\n\nns_of_interest &lt;- c(5, 10, 30, 50, 100)\nbeta_df_2 &lt;- filter(beta_df,n %in% ns_of_interest) %&gt;%\n  mutate(sample_size = as.factor(n))\n\n\nggplot(beta_df_2, aes(x = alpha, y = cover, color = sample_size)) +\n  geom_point() +\n  geom_smooth(aes(line = n ), se = FALSE) +\n  labs(\n    x = \"value of alpha and beta\",\n    y = \"actual coverage probability\",\n    title = \"Figure 3\",\n    subtitle = \"actual coverage probability based on parameter values\"\n  )\n\n\n\n\n\n\n\n\nFigure 3 plots the actual coverage probability per each value of alpha and beta. Points and lines are colored based on sample size, which are described in the legend. Alpha and beta have the same values, by the way. All the lines of best fit seem close to being horizontal, meaning that there most likely is not a relationship between the values of alpha/beta and the actual coverage probability of the data’s prediction interval. Based on the large overlap between lines, normal prediction intervals based on small amounts of data don’t seem more likely to deviate from the intended coverage probability of the data’s parent symmetric beta distribution, although they do have larger amounts of variability around their mean coverage probability."
  },
  {
    "objectID": "Beta_Simulation.html#conclusion",
    "href": "Beta_Simulation.html#conclusion",
    "title": "Simulation",
    "section": "Conclusion",
    "text": "Conclusion\nBy generating data from symmetric beta distributions with mu = .5 and making normal prediction intervals based on this data, I was able to assess the predictive accuracy and actual coverage probability of normal prediction intervals when applied to symmetric-beta data. Even given small sample sizes, normal prediction intervals seem to have good predictive accuracy and good coverage probability."
  },
  {
    "objectID": "Netflix_Analysis.html",
    "href": "Netflix_Analysis.html",
    "title": "Netflix Analysis",
    "section": "",
    "text": "library(RTextTools) \nlibrary(tidyverse)\nlibrary(tidytuesdayR)"
  },
  {
    "objectID": "Netflix_Analysis.html#netflix-horror-movies",
    "href": "Netflix_Analysis.html#netflix-horror-movies",
    "title": "Netflix Analysis",
    "section": "Netflix Horror Movies",
    "text": "Netflix Horror Movies\nIn this analysis of Netflix horror movies, I look at all movies with horror listed as a genre and see what other genres are also listed for said movies. I then create a bar plot comparing the number of other genres listed among Netflix horror movies.\nFirst, I filter for movies with horror listed as one of its genres and clean the variable listing movie genres so that it only includes genres that aren’t horror. This is all saved in the “horror_subgenre” object.\n\nhorror_subgenre &lt;- netflix %&gt;%\n  filter(str_detect(listed_in, \"Horror\"), type == \"Movie\") %&gt;%\n  mutate(listed_in = str_remove(listed_in, \", International Movies\")) %&gt;%\n  mutate(listed_in = str_remove(listed_in, \", Independent Movies\")) %&gt;%\n  mutate(listed_in = str_remove_all(listed_in, \"[,]\")) %&gt;%\n  mutate(listed_in = str_remove_all(listed_in, \"Movies\")) %&gt;%\n  mutate(listed_in = str_replace(listed_in, \"[:space:]&[:space:]\", \"&\")) %&gt;%\n  group_by(listed_in) %&gt;%\n  summarize(num = n()) %&gt;%\n  arrange(desc(num)) %&gt;%\n  mutate(listed_in = str_remove(listed_in, \"Horror\"))\n\nThen, I count the number of movies within “horror_subgenre” that list a specific secondary genre, with the secondary genres I consider being the following: thriller, comedy, romance, action/adventure, science fiction and fantasy, cult, documentary, and none. None means that the movie only has horror as its genre.\n\nnum_thrillers &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Thrillers\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Thrillers = 'str_detect(listed_in, \\\"Thrillers\\\")') %&gt;%\n  filter(Thrillers == TRUE) %&gt;%\n  mutate(genre = \"Thrillers\") %&gt;%\n  select(-Thrillers)\n\nnum_comedies &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Comedies\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Comedies = 'str_detect(listed_in, \\\"Comedies\\\")') %&gt;%\n  filter(Comedies == TRUE) %&gt;%\n  mutate(genre = \"Comedies\") %&gt;%\n  select(-Comedies)\n\n\nnum_action_adventure &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Action/Adventure\"))%&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Action_Adventure = 'str_detect(listed_in, \\\"Action/Adventure\\\")') %&gt;%\n  filter(Action_Adventure == TRUE) %&gt;%\n  mutate(genre = \"Action&Adventure\") %&gt;%\n  select(-Action_Adventure)\n\nnum_scifi_fantasy &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Sci-Fi&Fantasy\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(SciFi_Fantasy = 'str_detect(listed_in, \\\"Sci-Fi&Fantasy\\\")') %&gt;%\n  filter(SciFi_Fantasy == TRUE) %&gt;%\n  mutate(genre = \"SciFi&Fantasy\") %&gt;%\n  select(-SciFi_Fantasy)\n\nnum_cult &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Cult\")) %&gt;% \n  summarize(num = sum(num)) %&gt;%\n  rename(Cult = 'str_detect(listed_in, \\\"Cult\\\")') %&gt;%\n  filter(Cult == TRUE) %&gt;%\n  mutate(genre = \"Cult\") %&gt;%\n  select(-Cult)\n\nnum_documentaries &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Documentaries\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Documentaries = 'str_detect(listed_in, \\\"Documentaries\\\")') %&gt;%\n  filter(Documentaries == TRUE)%&gt;%\n  mutate(genre = \"Documentaties\") %&gt;%\n  select(-Documentaries)\n\nnum_romantic &lt;- horror_subgenre %&gt;%\n  group_by(str_detect(listed_in,\"Romantic\")) %&gt;%\n  summarize(num = sum(num)) %&gt;%\n  rename(Romantic = 'str_detect(listed_in, \\\"Romantic\\\")') %&gt;%\n  filter(Romantic == TRUE) %&gt;%\n  mutate(genre = \"Romantic\") %&gt;%\n  select(-Romantic)\n\nnum_horror &lt;- horror_subgenre %&gt;%\n  filter(listed_in == \" \") %&gt;%\n  mutate(listed_in = \"none\") %&gt;%\n  rename(genre = listed_in) %&gt;%\n  select(genre, num)\n\nhorror_df &lt;- rbind(num_thrillers, num_comedies, num_action_adventure, num_scifi_fantasy, num_cult, num_documentaries, num_romantic, num_horror ) %&gt;%\n  as.data.frame() %&gt;%\n  arrange(desc(num)) %&gt;%\n  select(genre, num)\nhorror_df\n\n          genre num\n1          none 125\n2     Thrillers 110\n3      Comedies  38\n4 SciFi&Fantasy  19\n5          Cult  12\n6 Documentaties   2\n7      Romantic   2\n\n\n\nggplot(horror_df, aes(x = genre, y = num)) +\n  geom_bar(stat = \"identity\", aes(fill = genre)) + labs(\n    title = \"Subgenres among netflix horror movies\",\n    x = \"Subgenre of horror movie\",\n    y = \"Count\"\n  ) + \n  scale_x_discrete(guide = guide_axis(n.dodge=3)) +\n  guides(fill=guide_legend(title=\"Subgenres\"))\n\n\n\n\n\n\n\n\nBased on this plot of the number of horror movies with specific secondary genres, it seems most netflix horror movies either do not have a secondary genre or have thriller as their secondary genre. Other secondary genres appear less present among Netflix horror movies."
  },
  {
    "objectID": "Netflix_Analysis.html#netflix-tv-shows",
    "href": "Netflix_Analysis.html#netflix-tv-shows",
    "title": "Netflix Analysis",
    "section": "Netflix TV Shows",
    "text": "Netflix TV Shows\nIn this analysis of Netflix tv shows, I look at the number of seasons present in Netflix shows released in different years. A season in a Netflix show is a set of episodes pertaining to said show that was greenlit to be released in a certain time period. A show having multiple seasons means different sets of episodes were allowed to be released at different periods of time.\n\ndata &lt;- netflix %&gt;% \n  filter(type == \"TV Show\") %&gt;%\n  mutate(num_seasons = as.numeric(str_extract(duration, \"\\\\d+\" )))\n\nggplot(data, aes(x = release_year, y = num_seasons)) +\n  geom_point() +\n  xlim(1970,2025)+\n  geom_smooth(se = FALSE) + \n  labs(\n    title = \"Relationship between release year and number of seasons of netflix tv show\",\n    x = \"Release year\",\n    y = \"Number of seasons\"\n  )\n\n\n\n\n\n\n\n\nBased on this plot, the number of seasons that a Netflix show has tends to be lower for shows released between 2005 and 2020 than for other shows. Due to the discreteness of values on the x-axis, multiple points are most likely overlapping. This explains why it appears the right side of the graph has less points below the line of best fit than above it even with the line trending downwards.\nData source here."
  },
  {
    "objectID": "Presentation.html#netflix-horror-movies",
    "href": "Presentation.html#netflix-horror-movies",
    "title": "Presentation",
    "section": "Netflix Horror Movies",
    "text": "Netflix Horror Movies\n\nhorror_df\n\n  num         genre\n1 125        Horror\n2 110     Thrillers\n3  38      Comedies\n4  19 SciFi&Fantasy\n5  12          Cult\n6   2 Documentaties\n7   2      Romantic"
  },
  {
    "objectID": "Presentation.html#diversity-of-horror",
    "href": "Presentation.html#diversity-of-horror",
    "title": "Presentation",
    "section": "Diversity of Horror",
    "text": "Diversity of Horror"
  },
  {
    "objectID": "Presentation.html#netflix-horror-movies-1",
    "href": "Presentation.html#netflix-horror-movies-1",
    "title": "Presentation",
    "section": "Netflix Horror Movies",
    "text": "Netflix Horror Movies"
  },
  {
    "objectID": "Presentation.html#beta-vs-normal-distribution",
    "href": "Presentation.html#beta-vs-normal-distribution",
    "title": "Presentation",
    "section": "Beta vs Normal Distribution",
    "text": "Beta vs Normal Distribution"
  },
  {
    "objectID": "Presentation.html#simulations",
    "href": "Presentation.html#simulations",
    "title": "Presentation",
    "section": "Simulations",
    "text": "Simulations\n\n\n     n PI_percentage lower upper cover alpha beta mean_in_interval\n1  164      3.141593   NaN   NaN   NaN   123  123               NA\n2   67      3.141593   NaN   NaN   NaN    17   17               NA\n3   78      3.141593   NaN   NaN   NaN   113  113               NA\n4  409      3.141593   NaN   NaN   NaN   195  195               NA\n5  337      3.141593   NaN   NaN   NaN    67   67               NA\n6   31      3.141593   NaN   NaN   NaN   151  151               NA\n7  332      3.141593   NaN   NaN   NaN    65   65               NA\n8  200      3.141593   NaN   NaN   NaN   187  187               NA\n9   88      3.141593   NaN   NaN   NaN    91   91               NA\n10 456      3.141593   NaN   NaN   NaN    55   55               NA"
  },
  {
    "objectID": "Presentation.html#results",
    "href": "Presentation.html#results",
    "title": "Presentation",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "Presentation.html#function-1-pi-interval-calculation",
    "href": "Presentation.html#function-1-pi-interval-calculation",
    "title": "Presentation",
    "section": "Function 1: PI Interval Calculation",
    "text": "Function 1: PI Interval Calculation\n\nPI &lt;- function(data, coverage_prob){ \n  #Generates a normal prediction interval with an intended coverage probability of coverage_prob based on a vector of numeric data\n  n &lt;- length(data)\n  lower_tscore &lt;- qt((1-coverage_prob)/2, df = n - 1)\n  upper_tscore &lt;- qt(((1-coverage_prob)/2) + coverage_prob, df = n - 1)\n  avg &lt;- mean(data)\n  stan_d &lt;- sd(data)\n  lower_bound &lt;- avg + lower_tscore*stan_d * sqrt(1 + (1/n))\n  upper_bound &lt;- avg + upper_tscore*stan_d * sqrt(1 + (1/n))\n  return(data.frame(PI_percentage = coverage_prob, lower = lower_bound, upper = upper_bound))\n}"
  },
  {
    "objectID": "Presentation.html#function-2-one-simulation-of-beta-generated-data",
    "href": "Presentation.html#function-2-one-simulation-of-beta-generated-data",
    "title": "Presentation",
    "section": "Function 2: One simulation of beta-generated data",
    "text": "Function 2: One simulation of beta-generated data\n\none_beta_simulation &lt;- function(n, alpha, beta, pi_prop){\n  #Assesses prediction accuracy and actual coverage probability of a normal prediction interval when used on a vector of numeric data of size n. The numeric data is generated from a beta distribution with parameters alpha and beta.\n  \n  cover_df &lt;- PI(rbeta(n, alpha, beta), pi_prop)\n  \n  cover_prop &lt;- pbeta(cover_df[1, \"upper\"], alpha, beta) - pbeta(cover_df[1, \"lower\"], alpha, beta) #this is the proportion of the data's parent distribution that is actually covered by the normal prediction interval generated for said data.\n  \n  mean_in_interval &lt;- .5 &gt;= cover_df[1, \"lower\"] & .5 &lt;= cover_df[1,\"upper\"]\n  param_df &lt;- data.frame(cover = cover_prop, alpha = rep(alpha, nrow(cover_df)), beta = rep(beta, nrow(cover_df)), mean_in_interval = mean_in_interval)\n  df &lt;- cbind(cover_df, param_df)\n  return(df)\n}"
  },
  {
    "objectID": "Presentation.html#function-3-multiple-beta-simulations",
    "href": "Presentation.html#function-3-multiple-beta-simulations",
    "title": "Presentation",
    "section": "Function 3: Multiple Beta simulations",
    "text": "Function 3: Multiple Beta simulations\n\nbeta_sims_n &lt;- function(n){\n  #Iterates over a vector of possible alpha = beta values and applies one_beta_simulation to each possible value of alpha/beta. All simulations use data of sample size n.\n  df1 &lt;- map(parameters,\\(param) one_beta_simulation(n, param, param, pi) ) %&gt;%\n  list_rbind()\n  df2 &lt;- data.frame(n = rep(n, nrow(df1)))\n  df &lt;- cbind(df2, df1)\n  return(df)\n}"
  },
  {
    "objectID": "Netflix_Analysis.html#introduction",
    "href": "Netflix_Analysis.html#introduction",
    "title": "Netflix Analysis",
    "section": "Introduction",
    "text": "Introduction\nThis project consists of me analyzing data about Netflix shows and movies, with said analysis focusing on two aspects of these: horror movies and number of seasons in said shows. The dataset used for this analysis can be found here. According to the Tidy Tuesday github page I found it in, it originates from Kaggle and was gathered by Shival Bansal. Here is what he says about the data:\n\nThis dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\nIn 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n\nHere is the data dictionary (sourced from here):\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nshow_id\ncharacter\nUnique ID for every Movie / Tv Show\n\n\ntype\ncharacter\nIdentifier - A Movie or TV Show\n\n\ntitle\ncharacter\nTitle of the Movie / Tv Show\n\n\ndirector\ncharacter\nDirector of the Movie/Show\n\n\ncast\ncharacter\nActors involved in the movie / show\n\n\ncountry\ncharacter\nCountry where the movie / show was produced\n\n\ndate_added\ncharacter\nDate it was added on Netflix\n\n\nrelease_year\ndouble\nActual Release year of the movie / show\n\n\nrating\ncharacter\nTV Rating of the movie / show\n\n\nduration\ncharacter\nTotal Duration - in minutes or number of seasons\n\n\nlisted_in\ncharacter\nGenre\n\n\ndescription\ncharacter\nSummary description of the film/show\n\n\n\n\nnetflix &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv')"
  },
  {
    "objectID": "Netflix_Analysis.html#data",
    "href": "Netflix_Analysis.html#data",
    "title": "Netflix Analysis",
    "section": "Data",
    "text": "Data\nThis project consists of me analyzing data about Netflix shows and movies, with said analysis focusing on two aspects of these: horror movies and number of seasons in said shows. The dataset used for this analysis can be found here. According to the Tidy Tuesday github page I found it in, it originates from Kaggle and was gathered by Shival Bansal. Here is what he says about the data:\n\nThis dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\nIn 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n\nHere is the data dictionary (sourced from here):\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nshow_id\ncharacter\nUnique ID for every Movie / Tv Show\n\n\ntype\ncharacter\nIdentifier - A Movie or TV Show\n\n\ntitle\ncharacter\nTitle of the Movie / Tv Show\n\n\ndirector\ncharacter\nDirector of the Movie/Show\n\n\ncast\ncharacter\nActors involved in the movie / show\n\n\ncountry\ncharacter\nCountry where the movie / show was produced\n\n\ndate_added\ncharacter\nDate it was added on Netflix\n\n\nrelease_year\ndouble\nActual Release year of the movie / show\n\n\nrating\ncharacter\nTV Rating of the movie / show\n\n\nduration\ncharacter\nTotal Duration - in minutes or number of seasons\n\n\nlisted_in\ncharacter\nGenre\n\n\ndescription\ncharacter\nSummary description of the film/show\n\n\n\n\nnetflix &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv')"
  },
  {
    "objectID": "SQL_Proj.html#analysis",
    "href": "SQL_Proj.html#analysis",
    "title": "Wideband Acoustic Immittance Data Visualization",
    "section": "",
    "text": "I plan to query data from the Wideband Acoustic Immittance Database, which is a repository of auditory measurements from different people. From this data, two graphs will be generated. One graph will replicate Figure 1 from Voss(2019) and the other will compare mean absorbance measurements between babies of different sexes over different frequencies using data from Aithal et al.(2013).\nThis is the abstract of Aithal et al.(2013):\n\nPresently, normative wideband reflectance data are available for neonates who have passed a distortion product otoacoustic emission test. However, passing the distortion product otoacoustic emission test alone does not ensure normal middle ear function. The objective of this study was to establish normative wideband reflectance data in healthy neonates with normal middle ear function, as justified by passing a battery of tests.\n\nVoss(2019) is a summarization of different studies analyzing auditory measurements among people.\n\nlibrary(RMariaDB)\nlibrary(dbplyr)\nlibrary(dplyr)\nlibrary(tidyverse)\n\n\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n #collect(Measurements)\n\n\nSELECT Measurements.Identifier,\n       Measurements.Frequency,\n       AVG(Absorbance) AS mean_absorbance,\n       CONCAT(PI_Info.AuthorsShortList,\" (\", PI_Info.Year, \")\",\" N=\", COUNT(DISTINCT Measurements.SubjectNumber) ,\"; \",Measurements.Instrument) AS studies\nFROM Measurements\nJOIN PI_Info ON Measurements.Identifier = PI_Info.Identifier\nWHERE PI_Info.AuthorsShortList IN (\"Abur et al.\", \"Feeney et al.\", \"Groon et al.\", \"Lewis and Neely\", \"Liu et al.\", \"Rosowski et al.\", \"Shahnaz et al.\", \"Shaver and Sun\", \"Sun et al.\", \"Voss and Allen\", \"Voss et al.\", \"Werner et al.\") AND Measurements.Frequency BETWEEN 0 and 8000\nGROUP BY Measurements.Identifier, Measurements.Frequency,  Measurements.Instrument;\n\n\ntable1 %&gt;%\n  ggplot(aes(x = Frequency, y = mean_absorbance)) +\n  geom_line(aes(color = studies), se = FALSE) + \n  labs(\n    title = \"Mean absorbance from publications in WAI database\"\n  )\n\n\n\n\n\n\n\n\n\nSELECT\n  Subjects.Sex AS sex,\n  Subjects.Race AS race,\n  Subjects.Ethnicity AS ethnicity,\n  Subjects.Identifier,\n  Measurements.Frequency AS freq,\n  AVG(Measurements.Absorbance) AS mean_absorbance\nFROM Subjects\nJOIN Measurements ON Subjects.SubjectNumber = Measurements.SubjectNumber \nWHERE Subjects.Identifier = \"Aithal_2013\" AND Measurements.Identifier = \"Aithal_2013\"\nGROUP BY ethnicity, race, sex, freq;\n\n\ntable2 %&gt;%\n  ggplot(aes(x = freq, y = mean_absorbance, color = sex)) +\n  geom_line(se = FALSE) +\n  labs(\n    title = \"Mean absorbance from babies of different sexes\"\n  )\n\n\n\n\n\n\n\n\nUsing SQL queries, I filtered through and sorted data in a manner that allowed me to compare absorbance measurements across babies of different sexes with data from Aithal(2013)and copy figure 1 of Voss(2019). I did this with 2 SQL queries and joined different tables from the same database to produce both graphs. Following each query, I used ggplot to plot mean absorbance measurements alongside frequency.\n\n\nAithal et al. 2013. “Normative wideband reflectance measures in healthy neonates.” International Journal of Pediatric Otorhinolaryngology 77 (1). https://doi.org/10.1016/j.ijporl.2012.09.02\nVoss, SE. 2019. “Resource Review.” Ear and Hearing 40 (6). https://doi.org/10.1097/AUD.0000000000000790."
  },
  {
    "objectID": "SQL_Proj.html#references",
    "href": "SQL_Proj.html#references",
    "title": "Wideband Acoustic Immittance Data Visualization",
    "section": "References",
    "text": "References\nAithal et al. 2013. “Normative wideband reflectance measures in healthy neonates.” International Journal of Pediatric Otorhinolaryngology 77 (1). https://doi.org/10.1016/j.ijporl.2012.09.02\nVoss, SE. 2019. “Resource Review.” Ear and Hearing 40 (6). https://doi.org/10.1097/AUD.0000000000000790."
  }
]